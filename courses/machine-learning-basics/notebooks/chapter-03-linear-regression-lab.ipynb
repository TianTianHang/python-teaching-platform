{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归实践\n",
    "\n",
    "## 实验目标\n",
    "\n",
    "本实验将使用 **Diabetes（糖尿病）数据集**来实践线性回归算法。\n",
    "\n",
    "Diabetes 数据集包含 442 个糖尿病患者的生理测量数据，目标是预测一年后的疾病进展程度（量化分数）。该数据集有 10 个生理特征：年龄、性别、BMI（身体质量指数）、血压等。\n",
    "\n",
    "## 实验内容\n",
    "\n",
    "1. **数据探索** - 了解数据集特征和分布\n",
    "2. **梯度下降实现** - 手动实现线性回归的梯度下降\n",
    "3. **特征标准化** - 比较标准化前后的性能差异\n",
    "4. **scikit-learn 实现** - 使用 sklearn 快速实现线性回归\n",
    "5. **模型评估** - 使用多种指标评估模型性能\n",
    "6. **可视化** - 绘制学习曲线和预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: 数据加载与探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# 加载 Diabetes 数据集\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# 创建 DataFrame\n",
    "feature_names = diabetes.feature_names\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(\"数据集信息:\")\n",
    "print(f\"样本数: {df.shape[0]}\")\n",
    "print(f\"特征数: {df.shape[1]}\")\n",
    "print(\"\\n特征名称:\", feature_names.tolist())\n",
    "print(\"\\n目标变量描述：\")\n",
    "print(f\"最小值: {y.min()}\")\n",
    "print(f\"最大值: {y.max()}\")\n",
    "print(f\"均值: {y.mean():.2f}\")\n",
    "print(f\"标准差: {y.std():.2f}\")\n",
    "print(\"\\n数据描述:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征说明：**\n",
    "- `age`: 年龄\n",
    "- `sex`: 性别\n",
    "- `bmi`: 身体质量指数\n",
    "- `bp`: 血压\n",
    "`s1`-`s6`: 6个血清测量值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: 手动实现梯度下降\n",
    "\n",
    "首先，让我们手动实现线性回归的梯度下降算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 2.1**：实现损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 实现均方误差损失函数\n",
    "\n",
    "def compute_mse(X, y, w, b):\n",
    "    \"\"\"\n",
    "    计算均方误差损失函数\n",
    "    J(w,b) = 1/(2m) * sum((h(x) - y)^2)\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    # 计算预测值 h(x) = X*w + b\n",
    "    predictions = None  # 替换为你的代码\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = None  # 替换为你的代码\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# 测试损失函数\n",
    "np.random.seed(42)\n",
    "w_test = np.random.randn(10) * 0.1\n",
    "b_test = 0\n",
    "\n",
    "mse = compute_mse(X, y, w_test, b_test)\n",
    "print(f\"初始损失（随机参数）: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 2.2**：实现梯度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 实现梯度计算\n",
    "\n",
    "def compute_gradients(X, y, w, b):\n",
    "    \"\"\"\n",
    "    计算梯度\n",
    "    dJ/dw = (1/m) * X.T * (X*w + b - y)\n",
    "    dJ/db = (1/m) * sum(X*w + b - y)\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    \n",
    "    # 计算预测值\n",
    "    predictions = None  # 替换为你的代码\n",
    "    \n",
    "    # 计算梯度\n",
    "    dw = None  # 替换为你的代码\n",
    "    db = None  # 替换为你的代码\n",
    "    \n",
    "    return dw, db\n",
    "\n",
    "# 测试梯度计算\n",
    "dw_test, db_test = compute_gradients(X[:5], y[:5], w_test, b_test)\n",
    "print(f\"权重梯度（前5个）: {dw_test[:5]}\")\n",
    "print(f\"偏置梯度: {db_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 2.3**：实现完整的梯度下降训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 实现梯度下降训练\n",
    "\n",
    "def train_linear_regression_gd(X, y, learning_rate=0.01, epochs=1000, verbose=True):\n",
    "    \"\"\"\n",
    "    使用梯度下降训练线性回归\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # 初始化参数\n",
    "    w = np.zeros(n)\n",
    "    b = 0\n",
    "    \n",
    "    # 记录损失\n",
    "    costs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 1. 计算当前损失\n",
    "        cost = None  # 替换为你的代码\n",
    "        costs.append(cost)\n",
    "        \n",
    "        # 2. 计算梯度\n",
    "        dw, db = None  # 替换为你的代码\n",
    "        \n",
    "        # 3. 更新参数\n",
    "        w = None  # 替换为你的代码\n",
    "        b = None  # 替换为你的代码\n",
    "        \n",
    "        if verbose and epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {cost:.4f}\")\n",
    "    \n",
    "    return w, b, costs\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "w, b, costs = train_linear_regression_gd(X_train, y_train, learning_rate=0.001, epochs=1000)\n",
    "\n",
    "print(\"\\n训练完成:\")\n",
    "print(f\"权重向量长度: {len(w)}\")\n",
    "print(f\"偏置: {b:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: 特征标准化影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 3.1**：手动实现特征标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 手动实现特征标准化\n",
    "\n",
    "def manual_normalize(X):\n",
    "    \"\"\"\n",
    "    标准化特征：使每个特征的均值为0，标准差为1\n",
    "    X' = (X - mean) / std\n",
    "    \"\"\"\n",
    "    # 计算均值和标准差\n",
    "    mean = None  # 替换为你的代码\n",
    "    std = None  # 替换为你的代码\n",
    "    \n",
    "    # 标准化\n",
    "    X_normalized = None  # 替换为你的代码\n",
    "    \n",
    "    return X_normalized, mean, std\n",
    "\n",
    "# 标准化训练集\n",
    "X_train_normalized, mean_train, std_train = manual_normalize(X_train)\n",
    "\n",
    "# 使用训练集的均值和标准差标准化测试集\n",
    "X_test_normalized = (X_test - mean_train) / std_train\n",
    "\n",
    "print(\"标准化前后对比（第一个特征）:\")\n",
    "print(f\"原始 - 均值: {X_train[:, 0].mean():.4f}, 标准差: {X_train[:, 0].std():.4f}\")\n",
    "print(f\"标准化 - 均值: {X_train_normalized[:, 0].mean():.4f}, 标准差: {X_train_normalized[:, 0].std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 3.2**：比较标准化前后的训练效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 比较标准化前后的训练效果\n",
    "\n",
    "# 1. 训练标准化后的模型\n",
    "w_normalized, b_normalized, costs_normalized = None  # 替换为你的代码\n",
    "\n",
    "# 2. 计算损失变化\n",
    "# 使用 compute_mse 函数计算\n",
    "\n",
    "print(\"标准化前 vs 标准化后:\")\n",
    "print(f\"最终损失（未标准化）: {final_cost_raw:.4f}\")\n",
    "print(f\"最终损失（标准化）: {final_cost_normalized:.4f}\")\n",
    "print(f\"损失下降: {((final_cost_raw - final_cost_normalized) / final_cost_raw * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: scikit-learn 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 4.1**：使用 sklearn 的 LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 使用 sklearn 的 LinearRegression\n",
    "\n",
    "# 1. 创建并训练模型（使用标准化后的数据）\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = None  # 替换为你的代码\n",
    "\n",
    "# 2. 获取模型参数\n",
    "w_sklearn = None  # 替换为你的代码\n",
    "b_sklearn = None  # 替换为你的代码\n",
    "\n",
    "print(\"sklearn 训练结果:\")\n",
    "print(f\"权重向量: {w_sklearn[:5]}...\")\n",
    "print(f\"偏置: {b_sklearn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 4.2**：比较手动实现和 sklearn 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 比较两种实现的参数\n",
    "\n",
    "# 计算参数差异\n",
    "weight_diff = None  # 替换为你的代码\n",
    "bias_diff = None  # 替换为你的代码\n",
    "\n",
    "print(\"参数对比:\")\n",
    "print(f\"权重差异: {weight_diff:.6f}\")\n",
    "print(f\"偏置差异: {bias_diff:.6f}\")\n",
    "print(\"\\n说明: sklearn 使用了解析解（最小二乘法），得到的是最优解；\")\n",
    "print(\"      而我们使用梯度下降，可能未完全收敛或学习率不合适。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: 模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 5.1**：评估模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 计算多种评估指标\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算多种评估指标\n",
    "    \"\"\"\n",
    "    mse = None  # 替换为你的代码\n",
    "    rmse = None  # 替换为你的代码\n",
    "    mae = None  # 替换为你的代码\n",
    "    r2 = None  # 替换为你的代码\n",
    "    \n",
    "    return {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R²': r2\n",
    "    }\n",
    "\n",
    # 使用手动训练的模型进行预测
    "y_pred_manual = None  # 替换为你的代码\n",
    "eval_manual = evaluate_model(y_test, y_pred_manual)\n",
    "\n",
    # 使用 sklearn 模型进行预测
    "y_pred_sklearn = None  # 替换为你的代码\n",
    "eval_sklearn = evaluate_model(y_test, y_pred_sklearn)\n",
    "\n",
    "print(\"模型评估对比:\")\n",
    "print(\"\\n手动实现:\")\n",
    "for metric, value in eval_manual.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nsklearn:\")\n",
    "for metric, value in eval_sklearn.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: 可视化与分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 6.1**：绘制学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 绘制梯度下降的学习曲线\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# 在这里绘制 costs 曲线\n",
    "\n",
    "plt.xlabel('迭代次数', fontsize=12)\n",
    "plt.ylabel('损失值 (MSE)', fontsize=12)\n",
    "plt.title('梯度下降学习曲线', fontsize=14)\n",
    "plt.grid(True, linestyle=':', alpha=0.5)\n",
    "plt.yscale('log')  # 使用对数坐标轴更好地观察变化\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 6.2**：绘制预测 vs 真实值散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 绘制预测值 vs 真实值散点图\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# 在这里绘制散点图\n",
    "\n",
    "# 添加 y=x 参考线（理想情况）\n",
    "min_val = min(y_test.min(), y_pred_sklearn.min())\n",
    "max_val = max(y_test.max(), y_pred_sklearn.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='理想预测', linewidth=2)\n",
    "\n",
    "plt.xlabel('真实值', fontsize=12)\n",
    "plt.ylabel('预测值', fontsize=12)\n",
    "plt.title('预测值 vs 真实值', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.5)\n",
    "plt.axis('equal')  # 保持坐标轴比例相等\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 6.3**：分析特征重要性"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# ===== 学生代码 =====\n",
     "# TODO: 分析特征重要性\n",
     "\n",
     "# 使用 sklearn 模型的系数\n",
     "feature_importance = None  # 替换为你的代码\n",
     "\n",
     "# 创建 DataFrame 显示特征重要性\n",
     "importance_df = pd.DataFrame({\n",
     "    'feature': feature_names,\n",
     "    'importance': np.abs(feature_importance)  # 取绝对值\n",
     "}).sort_values('importance', ascending=False)\n",
     "\n",
     "plt.figure(figsize=(12, 6))\n",
     "# 在这里绘制条形图\n",
     "\n",
     "plt.title('特征重要性（基于权重绝对值）', fontsize=14)\n",
     "plt.ylabel('重要性', fontsize=12)\n",
     "plt.grid(axis='y', linestyle=':', alpha=0.5)\n",
     "plt.show()\n",
     "\n",
     "print(\"特征重要性排序:\")\n",
     "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: 挑战练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**挑战 7.1**：批量梯度下降 vs 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# ===== 学生代码 =====\n",
     "# TODO: 实现随机梯度下降\n",
     "\n",
     "def train_linear_regression_sgd(X, y, learning_rate=0.001, epochs=1000, batch_size=32):\n",
     "    \"\"\"\n",
     "    随机梯度下降\n",
     "    \"\"\"\n",
     "    m, n = X.shape\n",
     "    \n",
     "    w = np.zeros(n)\n",
     "    b = 0\n",
     "    costs = []\n",
     "    \n",
     "    for epoch in range(epochs):\n",
     "        # 随机打乱数据\n",
     "        indices = np.random.permutation(m)\n",
     "        X_shuffled = X[indices]\n",
     "        y_shuffled = y[indices]\n",
     "        \n",
     "        batch_costs = []\n",
     "        for i in range(0, m, batch_size):\n",
     "            # 获取当前批次\n",
     "            X_batch = X_shuffled[i:i+batch_size]\n",
     "            y_batch = y_shuffled[i:i+batch_size]\n",
     "            \n",
     "            # 计算预测值\n",
     "            predictions = None  # 替换为你的代码\n",
     "            \n",
     "            # 计算梯度\n",
     "            dw = None  # 替换为你的代码\n",
     "            db = None  # 替换为你的代码\n",
     "            \n",
     "            # 更新参数\n",
     "            w = None  # 替换为你的代码\n",
     "            b = None  # 替换为你的代码\n",
     "            \n",
     "            # 计算当前批次损失\n",
     "            cost = compute_mse(X_batch, y_batch, w, b)\n",
     "            batch_costs.append(cost)\n",
     "        \n",
     "        # 计算平均损失\n",
     "        avg_cost = np.mean(batch_costs)\n",
     "        costs.append(avg_cost)\n",
     "        \n",
     "        if epoch % 100 == 0:\n",
     "            print(f\"Epoch {epoch}: Loss = {avg_cost:.4f}\")\n",
     "    \n",
     "    return w, b, costs\n",
     "\n",
     "# 使用 SGD 训练\n",
     "w_sgd, b_sgd, costs_sgd = train_linear_regression_sgd(X_train_normalized, y_train, \n",
     "                                                     learning_rate=0.01, epochs=1000)\n",
     "\n",
     "# 评估 SGD 模型\n",
     "y_pred_sgd = np.dot(X_test_normalized, w_sgd) + b_sgd\n",
     "eval_sgd = evaluate_model(y_test, y_pred_sgd)\n",
     "\n",
     "print(\"\\nSGD 训练结果:\")\n",
     "print(f\"权重向量长度: {len(w_sgd)}\")\n",
     "print(f\"偏置: {b_sgd:.4f}\")\n",
     "print(f\"测试集 R²: {eval_sgd['R²']:.4f}\")\n",
     "\n",
     "# 比较三种方法的收敛速度\n",
     "plt.figure(figsize=(10, 6))\n",
     "plt.plot(costs, label='批量梯度下降')\n",
     "plt.plot(costs_sgd, label='随机梯度下降')\n",
     "plt.xlabel('迭代次数', fontsize=12)\n",
     "plt.ylabel('损失值 (MSE)', fontsize=12)\n",
     "plt.title('不同梯度下降方法的收敛速度', fontsize=14)\n",
     "plt.legend()\n",
     "plt.yscale('log')\n",
     "plt.grid(True, linestyle=':', alpha=0.5)\n",
     "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**挑战 7.2**：特征工程与模型改进"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# ===== 学生代码 =====\n",
     "# TODO: 添加多项式特征并重新训练\n",
     "\n",
     "# 选择最重要的两个特征（根据之前的分析）\n",
     "top_features = ['bmi', 'bp']  # 假设这是最重要的两个特征\n",
     "feature_indices = [feature_names.index(f) for f in top_features]\n",
     "\n",
     "# 创建多项式特征：x^2\n",
     "X_poly = np.column_stack([\n",
     "    X_train_normalized[:, feature_indices],  # 原始特征\n",
     "    X_train_normalized[:, feature_indices] ** 2  # 平方项\n",
     "])\n",
     "\n",
     "# 测试集也需要同样的转换\n",
     "X_test_poly = np.column_stack([\n",
     "    X_test_normalized[:, feature_indices],\n",
     "    X_test_normalized[:, feature_indices] ** 2\n",
     "])\n",
     "\n",
     "# 使用 sklearn 训练多项式回归模型\n",
     "from sklearn.linear_model import LinearRegression\n",
     "model_poly = None  # 替换为你的代码\n",
     "model_poly.fit(X_poly, y_train)\n",
     "\n",
     "# 评估多项式模型\n",
     "y_pred_poly = None  # 替换为你的代码\n",
     "eval_poly = evaluate_model(y_test, y_pred_poly)\n",
     "\n",
     "print(\"\\n多项式回归结果:\")\n",
     "print(f\"特征数量: {X_poly.shape[1]}\")\n",
     "print(f\"测试集 R²: {eval_poly['R²']:.4f}\")\n",
     "print(f\"相比线性回归提升: {(eval_poly['R²'] - eval_sklearn['R²']) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 实验总结\n",
    "\n",
    "恭喜你完成了线性回归实践！通过本实验，你应该掌握了：\n",
    "\n",
    "1. ✓ 手动实现线性回归的梯度下降算法\n",
    "2. ✓ 理解特征标准化对训练的影响\n",
    "3. ✓ 使用 scikit-learn 快速实现线性回归\n",
    "4. ✓ 评估模型的多种指标（MSE, RMSE, MAE, R²）\n",
    "5. ✓ 可视化学习曲线和预测结果\n",
    "6. ✓ 比较批量梯度下降和随机梯度下降\n",
    "7. ✓ 使用多项式特征进行简单特征工程\n",
    "\n",
    "线性回归是机器学习的基础，理解其原理和实现对于学习更复杂的算法至关重要。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
