{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: K 近邻算法 (KNN) 实践\n",
    "\n",
    "## 实验概述\n",
    "\n",
    "在本实验中，你将使用 **Digits 数据集**（手写数字识别）来学习 K 近邻算法的实现和应用。Digits 数据集包含 1797 个 8x8 像素的手写数字图像，每个图像对应 0-9 中的一个数字。\n",
    "\n",
    "### 实验目标\n",
    "\n",
    "1. 理解 KNN 算法的基本原理\n",
    "2. 实现欧氏距离计算\n",
    "3. 手动实现 KNN 分类器\n",
    "4. 使用 scikit-learn 的 KNN 模型\n",
    "5. 找到最优的 K 值\n",
    "6. 可视化决策边界和混淆矩阵\n",
    "\n",
    "### 数据集信息\n",
    "\n",
    "- **样本数量**: 1797\n",
    "- **特征数量**: 64 (8x8 像素)\n",
    "- **类别数量**: 10 (数字 0-9)\n",
    "- **特征**: 每个特征的值是 0-16 之间的灰度值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: 数据加载与探索\n",
    "\n",
    "### 1.1 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"库导入成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 加载 Digits 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 加载数据集\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "print(\"数据集信息:\")\n",
    "print(f\"样本数量: {X.shape[0]}\")\n",
    "print(f\"特征数量: {X.shape[1]}\")\n",
    "print(f\"图像尺寸: 8x8\")\n",
    "print(f\"类别数量: {len(np.unique(y))}\")\n",
    "print(f\"\\n类别: {np.unique(y)}\")\n",
    "print(f\"\\n特征值范围: [{X.min():.1f}, {X.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 可视化手写数字图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 可视化前 20 个数字图像\n",
    "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(20):\n",
    "    axes[i].imshow(digits.images[i], cmap='gray')\n",
    "    axes[i].set_title(f'标签: {y[i]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Digits 数据集 - 前20个样本', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 数据集统计\n",
    "\n",
    "**任务**: 统计每个数字的样本数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 统计每个数字的样本数量\n",
    "# 提示: 使用 np.bincount() 或 Counter\n",
    "\n",
    "label_counts = None  # 替换为你的代码\n",
    "\n",
    "print(\"每个数字的样本数量:\")\n",
    "for digit, count in enumerate(label_counts):\n",
    "    print(f\"  数字 {digit}: {count} 个样本\")\n",
    "\n",
    "# 可视化类别分布\n",
    "plt.figure(figsize=(10, 5))\n",
    "# TODO: 绘制柱状图显示每个数字的样本数量\n",
    "# 提示: 使用 plt.bar()\n",
    "\n",
    "plt.xlabel('数字')\n",
    "plt.ylabel('样本数量')\n",
    "plt.title('Digits 数据集 - 类别分布')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 数据预处理与划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 特征归一化 (0-1 范围)\n",
    "X_normalized = X / 16.0  # 像素值范围是 0-16\n",
    "\n",
    "# 划分数据集 (80% 训练, 20% 测试)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_normalized, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape}\")\n",
    "print(f\"测试集大小: {X_test.shape}\")\n",
    "print(f\"\\n特征值范围 (归一化后): [{X_normalized.min():.1f}, {X_normalized.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: 距离度量实现\n",
    "\n",
    "### 2.1 欧氏距离\n",
    "\n",
    "**任务**: 实现欧氏距离函数 $d(x, y) = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    计算两个向量之间的欧氏距离\n",
    "    \n",
    "    参数:\n",
    "    x1: 第一个向量 (n_features,)\n",
    "    x2: 第二个向量 (n_features,)\n",
    "    \n",
    "    返回:\n",
    "    欧氏距离\n",
    "    \"\"\"\n",
    "    # TODO: 实现欧氏距离计算\n",
    "    pass\n",
    "\n",
    "# 测试欧氏距离函数\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7, 8])\n",
    "dist = euclidean_distance(a, b)\n",
    "print(f\"欧氏距离测试: d({a}, {b}) = {dist:.4f}\")\n",
    "# 预期输出: 8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 曼哈顿距离\n",
    "\n",
    "**任务**: 实现曼哈顿距离函数 $d(x, y) = \\sum_{i=1}^{n}|x_i - y_i|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "def manhattan_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    计算两个向量之间的曼哈顿距离\n",
    "    \n",
    "    参数:\n",
    "    x1: 第一个向量\n",
    "    x2: 第二个向量\n",
    "    \n",
    "    返回:\n",
    "    曼哈顿距离\n",
    "    \"\"\"\n",
    "    # TODO: 实现曼哈顿距离计算\n",
    "    pass\n",
    "\n",
    "# 测试曼哈顿距离函数\n",
    "dist_m = manhattan_distance(a, b)\n",
    "print(f\"曼哈顿距离测试: d({a}, {b}) = {dist_m:.4f}\")\n",
    "# 预期输出: 16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 批量距离计算\n",
    "\n",
    "**任务**: 计算一个样本到所有训练样本的距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "def compute_distances(X_train, x_test, metric='euclidean'):\n",
    "    \"\"\"\n",
    "    计算测试样本到所有训练样本的距离\n",
    "    \n",
    "    参数:\n",
    "    X_train: 训练集 (n_samples, n_features)\n",
    "    x_test: 测试样本 (n_features,)\n",
    "    metric: 距离度量 ('euclidean' 或 'manhattan')\n",
    "    \n",
    "    返回:\n",
    "    距离数组 (n_samples,)\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    \n",
    "    # TODO: 遍历训练集，计算每个样本到测试样本的距离\n",
    "    # 提示: 使用 for 循环 + distance 函数\n",
    "    \n",
    "    return np.array(distances)\n",
    "\n",
    "# 测试\n",
    "x_sample = X_test[0]\n",
    "dists = compute_distances(X_train, x_sample, metric='euclidean')\n",
    "print(f\"测试样本到训练集的距离 (前10个): {dists[:10]}\")\n",
    "print(f\"最小距离: {dists.min():.4f}\")\n",
    "print(f\"最大距离: {dists.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: 手动实现 KNN 分类器\n",
    "\n",
    "### 3.1 实现预测函数\n",
    "\n",
    "**任务**: 实现 KNN 预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "def knn_predict(X_train, y_train, x_test, k=5):\n",
    "    \"\"\"\n",
    "    KNN 分类预测\n",
    "    \n",
    "    参数:\n",
    "    X_train: 训练集特征\n",
    "    y_train: 训练集标签\n",
    "    x_test: 测试样本\n",
    "    k: 邻居数量\n",
    "    \n",
    "    返回:\n",
    "    预测类别\n",
    "    \"\"\"\n",
    "    # TODO 1: 计算测试样本到所有训练样本的距离\n",
    "    distances = None  # 替换为你的代码\n",
    "    \n",
    "    # TODO 2: 获取距离最近的 k 个样本的索引\n",
    "    # 提示: 使用 np.argsort()\n",
    "    k_indices = None  # 替换为你的代码\n",
    "    \n",
    "    # TODO 3: 获取 k 个最近邻的标签\n",
    "    k_nearest_labels = None  # 替换为你的代码\n",
    "    \n",
    "    # TODO 4: 多数投票，返回最常见的类别\n",
    "    # 提示: 使用 Counter 和 most_common()\n",
    "    prediction = None  # 替换为你的代码\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# 测试 KNN 预测\n",
    "x_test_sample = X_test[0]\n",
    "true_label = y_test[0]\n",
    "pred_label = knn_predict(X_train, y_train, x_test_sample, k=5)\n",
    "\n",
    "print(f\"真实标签: {true_label}\")\n",
    "print(f\"预测标签: {pred_label}\")\n",
    "print(f\"预测{'正确' if true_label == pred_label else '错误'}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 批量预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "def knn_predict_batch(X_train, y_train, X_test, k=5):\n",
    "    \"\"\"\n",
    "    对测试集进行批量预测\n",
    "    \n",
    "    参数:\n",
    "    X_train: 训练集特征\n",
    "    y_train: 训练集标签\n",
    "    X_test: 测试集特征\n",
    "    k: 邻居数量\n",
    "    \n",
    "    返回:\n",
    "    预测标签数组\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    # TODO: 遍历测试集，对每个样本进行预测\n",
    "    # 注意: 这个过程可能较慢，因为 KNN 需要计算大量距离\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "# 在小测试集上测试（只取前20个样本加快速度）\n",
    "print(\"在测试集子集上进行预测（前20个样本）...\")\n",
    "y_pred_manual = knn_predict_batch(X_train, y_train, X_test[:20], k=5)\n",
    "\n",
    "accuracy = np.mean(y_pred_manual == y_test[:20])\n",
    "print(f\"手动实现的 KNN 准确率: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: 使用 scikit-learn 的 KNN\n",
    "\n",
    "### 4.1 创建 KNN 分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 创建 KNN 分类器\n",
    "# 提示: 使用 KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn = None  # 替换为你的代码\n",
    "\n",
    "# TODO: 训练模型（注意：KNN 是惰性学习，训练过程只是存储数据）\n",
    "\n",
    "# TODO: 在训练集和测试集上预测\n",
    "y_train_pred = None\n",
    "y_test_pred = None\n",
    "\n",
    "# TODO: 计算准确率\n",
    "train_acc = None\n",
    "test_acc = None\n",
    "\n",
    "print(f\"KNN 分类器 (K=5):\")\n",
    "print(f\"  训练集准确率: {train_acc:.4f}\")\n",
    "print(f\"  测试集准确率: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 寻找最优 K 值\n",
    "\n",
    "**任务**: 尝试不同的 K 值，找到最优的 K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# 尝试不同的 K 值\n",
    "k_values = list(range(1, 31, 2))  # 1, 3, 5, ..., 29\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# TODO: 遍历不同的 K 值，记录训练集和测试集的准确率\n",
    "\n",
    "\n",
    "# 找到最佳 K 值\n",
    "best_k = k_values[np.argmax(test_scores)]\n",
    "best_score = max(test_scores)\n",
    "\n",
    "print(f\"最佳 K 值: {best_k}\")\n",
    "print(f\"最佳测试集准确率: {best_score:.4f}\")\n",
    "\n",
    "# 绘制 K 值与准确率的关系\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_values, train_scores, 'o-', label='训练集准确率', linewidth=2)\n",
    "plt.plot(k_values, test_scores, 's-', label='测试集准确率', linewidth=2)\n",
    "plt.axvline(x=best_k, color='green', linestyle='--', label=f'最佳 K={best_k}')\n",
    "plt.xlabel('K 值')\n",
    "plt.ylabel('准确率')\n",
    "plt.title('K 值对模型性能的影响')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 加权 KNN\n",
    "\n",
    "**任务**: 比较均匀权重和距离权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# 创建两个 KNN 模型：均匀权重和距离权重\n",
    "\n",
    "# TODO: 创建均匀权重的 KNN (weights='uniform')\n",
    "knn_uniform = None  # 替换为你的代码\n",
    "\n",
    "# TODO: 创建距离权重的 KNN (weights='distance')\n",
    "# 距离越近的邻居权重越大\n",
    "knn_distance = None  # 替换为你的代码\n",
    "\n",
    "# 训练并评估\n",
    "knn_uniform.fit(X_train, y_train)\n",
    "knn_distance.fit(X_train, y_train)\n",
    "\n",
    "uniform_acc = knn_uniform.score(X_test, y_test)\n",
    "distance_acc = knn_distance.score(X_test, y_test)\n",
    "\n",
    "print(\"权重策略比较:\")\n",
    "print(f\"  均匀权重 (uniform): {uniform_acc:.4f}\")\n",
    "print(f\"  距离权重 (distance): {distance_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 不同距离度量的比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 比较不同的距离度量\n",
    "metrics = ['euclidean', 'manhattan', 'minkowski']\n",
    "results = []\n",
    "\n",
    "for metric in metrics:\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k, metric=metric)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = knn.score(X_train, y_train)\n",
    "    test_acc = knn.score(X_test, y_test)\n",
    "    \n",
    "    results.append({\n",
    "        'metric': metric,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"不同距离度量的比较:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: 模型评估与可视化\n",
    "\n",
    "### 5.1 使用最佳模型进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 使用最佳参数创建模型\n",
    "best_knn = None  # 替换为你的代码，使用最佳的 K 值\n",
    "\n",
    "# TODO: 训练模型并预测\n",
    "\n",
    "y_pred_best = None  # 替换为你的代码\n",
    "\n",
    "# 显示分类报告\n",
    "print(\"分类报告:\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "print(f\"测试集准确率: {accuracy_score(y_test, y_pred_best):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 混淆矩阵可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 计算混淆矩阵\n",
    "cm = None  # 替换为你的代码\n",
    "\n",
    "# 可视化混淆矩阵\n",
    "plt.figure(figsize=(10, 8))\n",
    "# TODO: 使用 seaborn 绘制热力图\n",
    "# 提示: sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.xlabel('预测类别')\n",
    "plt.ylabel('真实类别')\n",
    "plt.title('混淆矩阵 - 手写数字识别')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 可视化预测结果\n",
    "\n",
    "**任务**: 显示一些预测正确和错误的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 找出预测正确和错误的样本\n",
    "\n",
    "correct_indices = None  # 替换为你的代码 - 预测正确的样本索引\n",
    "incorrect_indices = None  # 替换为你的代码 - 预测错误的样本索引\n",
    "\n",
    "print(f\"预测正确数量: {len(correct_indices)}\")\n",
    "print(f\"预测错误数量: {len(incorrect_indices)}\")\n",
    "\n",
    "# 可视化一些预测结果\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "\n",
    "# 第一行: 预测正确的样本\n",
    "for i in range(5):\n",
    "    idx = correct_indices[i]\n",
    "    img = X_test[idx].reshape(8, 8)\n",
    "    axes[0, i].imshow(img, cmap='gray')\n",
    "    axes[0, i].set_title(f'真实:{y_test[idx]}, 预测:{y_pred_best[idx]}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# 第二行: 预测错误的样本\n",
    "for i in range(5):\n",
    "    if i < len(incorrect_indices):\n",
    "        idx = incorrect_indices[i]\n",
    "        img = X_test[idx].reshape(8, 8)\n",
    "        axes[1, i].imshow(img, cmap='gray')\n",
    "        axes[1, i].set_title(f'真实:{y_test[idx]}, 预测:{y_pred_best[idx]}', color='red')\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('预测正确', fontsize=12)\n",
    "axes[1, 0].set_ylabel('预测错误', fontsize=12)\n",
    "plt.suptitle('KNN 预测结果示例', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: 挑战练习\n",
    "\n",
    "### 6.1 交叉验证\n",
    "\n",
    "**任务**: 使用交叉验证评估模型稳定性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 使用 5 折交叉验证评估模型\n",
    "# 提示: cross_val_score(estimator, X, y, cv=5)\n",
    "\n",
    "cv_scores = None  # 替换为你的代码\n",
    "\n",
    "print(\"5 折交叉验证结果:\")\n",
    "print(f\"每折分数: {cv_scores}\")\n",
    "print(f\"平均分数: {cv_scores.mean():.4f}\")\n",
    "print(f\"标准差: {cv_scores.std():.4f}\")\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(1, 6), cv_scores, alpha=0.7, edgecolor='black')\n",
    "plt.axhline(y=cv_scores.mean(), color='red', linestyle='--',\n",
    "            label=f'平均分: {cv_scores.mean():.4f}')\n",
    "plt.xlabel('折数')\n",
    "plt.ylabel('准确率')\n",
    "plt.title('5 折交叉验证结果')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 决策边界可视化（简化版）\n",
    "\n",
    "**任务**: 使用 PCA 降维后可视化决策边界"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# TODO: 使用 PCA 将数据降维到 2D\n",
    "# 提示: PCA(n_components=2)\n",
    "\n",
    "pca = None  # 替换为你的代码\n",
    "X_train_2d = None  # 替换为你的代码\n",
    "X_test_2d = None  # 替换为你的代码\n",
    "\n",
    "# 在 2D 数据上训练 KNN\n",
    "knn_2d = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_2d.fit(X_train_2d, y_train)\n",
    "\n",
    "# 创建网格\n",
    "x_min, x_max = X_train_2d[:, 0].min() - 1, X_train_2d[:, 0].max() + 1\n",
    "y_min, y_max = X_train_2d[:, 1].min() - 1, X_train_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# 预测网格\n",
    "Z = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# 绘制决策边界\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 左图: 训练集\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train,\n",
    "                       cmap='tab10', alpha=0.6, s=30)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='tab10')\n",
    "plt.xlabel('主成分 1')\n",
    "plt.ylabel('主成分 2')\n",
    "plt.title('训练集 - PCA 降维后的决策边界')\n",
    "plt.colorbar(scatter, label='数字')\n",
    "\n",
    "# 右图: 测试集\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(X_test_2d[:, 0], X_test_2d[:, 1], c=y_test,\n",
    "                       cmap='tab10', alpha=0.6, s=30)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='tab10')\n",
    "plt.xlabel('主成分 1')\n",
    "plt.ylabel('主成分 2')\n",
    "plt.title('测试集 - PCA 降维后的决策边界')\n",
    "plt.colorbar(scatter, label='数字')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 性能分析\n",
    "\n",
    "**任务**: 分析 K 值对预测时间的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "import time\n",
    "\n",
    "# 测试不同 K 值的预测时间\n",
    "k_values = [1, 5, 11, 21, 31, 51]\n",
    "prediction_times = []\n",
    "\n",
    "print(\"测量不同 K 值的预测时间...\\n\")\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # 测量预测时间\n",
    "    start = time.time()\n",
    "    knn.predict(X_test)\n",
    "    end = time.time()\n",
    "    \n",
    "    elapsed = end - start\n",
    "    prediction_times.append(elapsed)\n",
    "    print(f\"K={k:2d}: 预测时间 = {elapsed:.4f} 秒\")\n",
    "\n",
    "# 绘制结果\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_values, prediction_times, 'o-', linewidth=2)\n",
    "plt.xlabel('K 值')\n",
    "plt.ylabel('预测时间 (秒)')\n",
    "plt.title('K 值对预测时间的影响')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n结论:\")\n",
    "print(\"- KNN 的预测时间随着 K 值增加略有增加\")\n",
    "print(\"- KNN 的主要时间开销是距离计算，这与 K 值关系不大\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "恭喜你完成了 KNN 实验！在本实验中，你学习了：\n",
    "\n",
    "1. ✅ **KNN 原理**: 基于最近邻居的多数投票\n",
    "2. ✅ **距离度量**: 欧氏距离、曼哈顿距离\n",
    "3. ✅ **手动实现**: 从零实现 KNN 分类器\n",
    "4. ✅ **scikit-learn KNN**: 使用 KNeighborsClassifier\n",
    "5. ✅ **K 值选择**: 找到最优的邻居数量\n",
    "6. ✅ **模型评估**: 准确率、混淆矩阵、交叉验证\n",
    "\n",
    "### 关键要点\n",
    "\n",
    "- **K 值选择**: K 太小容易过拟合，K 太大容易欠拟合\n",
    "- **距离度量**: 欧氏距离最常用，曼哈顿距离对异常值更鲁棒\n",
    "- **加权投票**: 距离权重通常比均匀权重效果好\n",
    "- **特征缩放**: KNN 对特征尺度敏感，需要归一化\n",
    "- **计算成本**: KNN 是惰性学习，预测时需要计算大量距离\n",
    "\n",
    "### 进一步学习\n",
    "\n",
    "- 尝试其他距离度量（如余弦相似度）\n",
    "- 学习 KD 树和 Ball 树等加速算法\n",
    "- 探索 KNN 在回归问题中的应用 (KNeighborsRegressor)\n",
    "- 研究维度灾难及其缓解方法"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
