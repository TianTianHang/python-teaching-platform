{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归实践\n",
    "\n",
    "## 实验目标\n",
    "\n",
    "本实验将使用 **Breast Cancer（乳腺癌）数据集**来实践逻辑回归算法。\n",
    "\n",
    "Breast Cancer 数据集包含乳腺癌患者的细胞核测量特征，目标是预测肿瘤是良性（malignant）还是恶性（benign）。这是一个二分类问题，属于分类任务。\n",
    "\n",
    "## 实验内容\n",
    "\n",
    "1. **数据探索** - 了解乳腺癌数据集的特征和分布\n",
    "2. **Sigmoid 函数** - 实现和理解 Sigmoid 激活函数\n",
    "3. **损失函数实现** - 手动实现交叉熵损失函数\n",
    "4. **梯度下降** - 实现逻辑回归的梯度下降算法\n",
    "5. **scikit-learn 实现** - 使用 sklearn 快速实现逻辑回归\n",
    "6. **模型评估** - 准确率、精确率、召回率、F1 分数\n",
    "7. **可视化决策边界** - 展示分类效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: 数据加载与探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# 加载 Breast Cancer 数据集\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# 创建 DataFrame\n",
    "feature_names = cancer.feature_names\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# 将 0/1 转换为 malignant/benign\n",
    "df['target_name'] = df['target'].map({0: 'malignant', 1: 'benign'})\n",
    "\n",
    "print(\"数据集信息:\")\n",
    "print(f\"样本数: {df.shape[0]}\")\n",
    "print(f\"特征数: {df.shape[1] - 2}\")  # 不包括 target 和 target_name\n",
    "print(\"\\n类别分布:\")\n",
    "print(df['target_name'].value_counts())\n",
    "print(\"\\n特征名称（前10个）:\", feature_names[:10].tolist())\n",
    "print(\"\\n数据描述（前5个特征）:\")\n",
    "print(df.iloc[:, :5].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征说明：**\n",
    "- 数据包含 30 个特征，都是肿瘤细胞核的测量值\n",
    - 包括半径、纹理、周长、面积、平滑度、紧凑度、凹凸性等\n",
    "- 目标：0 = malignant（恶性），1 = benign（良性）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Sigmoid 函数实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 2.1**：实现 Sigmoid 函数\n",
    "\n",
    Sigmoid 函数定义：$\sigma(z) = \\frac{1}{1 + e^{-z}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 实现 Sigmoid 函数\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Sigmoid 激活函数\n",
    "    \n",
    "    Args:\n",
    "        z: 线性组合结果（可以是标量或数组）\n",
    "    \n",
    "    Returns:\n",
    "        概率值，范围 (0, 1)\n",
    "    \"\"\"\n",
    "    pass  # 删除 pass 并填写你的代码\n",
    "\n",
    "# 测试 Sigmoid 函数\n",
    "test_values = [-10, -5, -1, 0, 1, 5, 10]\n",
    "print(\"Sigmoid 函数值测试:\")\n",
    "for val in test_values:\n",
    "    print(f\"sigmoid({val:3d}) = {sigmoid(val):.6f}\")\n",
    "\n",
    "# 预期输出：\n",
    "# sigmoid(-10) = 0.000045\n",
    "# sigmoid(-5) = 0.006693\n",
    "# sigmoid(-1) = 0.268941\n",
    "# sigmoid(0) = 0.500000\n",
    "# sigmoid(1) = 0.731059\n",
    "# sigmoid(5) = 0.993307\n",
    "# sigmoid(10) = 0.999955"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习 2.2**：可视化 Sigmoid 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 绘制 Sigmoid 函数曲线\n",
    "\n",
    "# 创建输入值范围\n",
    "z = np.linspace(-10, 10, 100)\n",
    "sigma_values = None  # 替换为你的代码\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# 在这里绘制曲线\n",
    "\n",
    "# 添加参考线\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', label='阈值 0.5')\n",
    "plt.axvline(x=0, color='g', linestyle='--', label='z=0')\n",
    "\n",
    "plt.xlabel('z（线性组合）', fontsize=12)\n",
    "plt.ylabel('sigmoid(z)', fontsize=12)\n",
    "plt.title('Sigmoid 函数曲线', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: 交叉熵损失函数"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "**练习 3.1**：实现交叉熵损失函数\n",
    "\n",
    交叉熵损失：$J(w,b) = -\\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}\\log(\\hat{y}^{(i)}) + (1-y^{(i)})\\log(1-\\hat{y}^{(i)})]$"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 实现交叉熵损失函数\n",
    "\n",
    "def compute_bce_loss(X, y, w, b):\n",
    "    \"\"\"\n",
    "    计算二元交叉熵损失\n",
    "    \n",
    "    Args:\n",
    "        X: 特征数据，形状 (m, n)\n",
    "        y: 标签数据，形状 (m,)，值为 0 或 1\n",
    "        w: 权重，形状 (n,)\n",
    "        b: 偏置\n",
    "    \n",
    "    Returns:\n",
    "        损失值\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    \n",
    "    # 1. 计算线性组合\n",
    "    z = None  # 替换为你的代码\n",
    "    \n",
    "    # 2. 计算预测概率\n",
    "    y_pred = None  # 替换为你的代码\n",
    "    \n",
    "    # 3. 避免数值溢出（限制预测值范围）\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    \n",
    "    # 4. 计算交叉熵损失\n",
    "    loss = None  # 替换为你的代码\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# 测试损失函数\n",
    "print(\"损失函数测试:\")\n",
    "print(f\"预测 0.9，真实 1: 损失 = {-np.log(0.9):.4f}\")\n",
    "print(f\"预测 0.1，真实 0: 损失 = {-np.log(0.9):.4f}\")\n",
    "print(f\"预测 0.1，真实 1: 损失 = {-np.log(0.1):.4f}\")\n",
    "print(f\"预测 0.9，真实 0: 损失 = {-np.log(0.1):.4f}\")\n",
    "\n",
    "print(\"\\n说明: 正确预测时损失小，错误预测时损失大\")"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "**练习 3.2**：实现梯度计算\n",
    "\n",
    梯度公式：\n",
    "\\[\\frac{\\partial J}{\\partial w} = \\frac{1}{m}X^T(\\hat{y} - y)\\]\n",
    "\\[\\frac{\\partial J}{\\partial b} = \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{y}^{(i)} - y^{(i)})\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 实现梯度计算\n",
    "\n",
    "def compute_gradients_logistic(X, y, w, b):\n",
    "    \"\"\"\n",
    "    计算逻辑回归的梯度\n",
    "    \n",
    "    Args:\n",
    "        X: 特征数据，形状 (m, n)\n",
    "        y: 标签数据，形状 (m,)，值为 0 或 1\n",
    "        w: 权重，形状 (n,)\n",
    "        b: 偏置\n",
    "    \n",
    "    Returns:\n",
    "        dw: 权重梯度，形状 (n,)\n",
    "        db: 偏置梯度\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    \n",
    "    # 1. 计算线性组合和预测概率\n",
    "    z = None  # 替换为你的代码\n",
    "    y_pred = None  # 替换为你的代码\n",
    "    \n",
    "    # 2. 计算梯度\n",
    "    dw = None  # 替换为你的代码\n",
    "    db = None  # 替换为你的代码\n",
    "    \n",
    "    return dw, db\n",
    "\n",
    "# 测试梯度计算\n",
    "np.random.seed(42)\n",
    "w_test = np.random.randn(2) * 0.1\n",
    "b_test = 0\n",
    "X_test = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "y_test = np.array([0, 1, 0])\n",
    "\n",
    "dw_test, db_test = compute_gradients_logistic(X_test, y_test, w_test, b_test)\n",
    "print(f\"\\n梯度测试:\")\n",
    "print(f\"权重梯度: {dw_test}\")\n",
    "print(f\"偏置梯度: {db_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "---\n",
    "## Part 4: 手动实现逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "**练习 4.1**：简化数据集（仅使用两个特征）\n",
    "\n",
    为了便于可视化和理解，我们先只使用两个特征来构建模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 选择最重要的两个特征\n",
    "\n",
    "# 选择 mean radius 和 mean texture 两个特征\n",
    "feature_cols = ['mean radius', 'mean texture']  # 替换为你的代码\n",
    "X_selected = None  # 替换为你的代码\n",
    "y_selected = None  # 替换为你的代码\n",
    "\n",
    "print(f\"选择的特征: {feature_cols}\")\n",
    "print(f\"数据形状: {X_selected.shape}\")\n",
    "\n",
    # 划分训练集和测试集
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y_selected, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "**练习 4.2**：特征标准化"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 对特征进行标准化\n",
    "\n",
    "def manual_normalize(X):\n",
    "    \"\"\"\n",
    "    手动实现特征标准化\n",
    "    \"\"\"\n",
    "    mean = None  # 替换为你的代码\n",
    "    std = None  # 替换为你的代码\n",
    "    X_normalized = None  # 替换为你的代码\n",
    "    return X_normalized, mean, std\n",
    "\n",
    "# 标准化训练集\n",
    "X_train_norm, mean_train, std_train = None  # 替换为你的代码\n",
    "\n",
    # 使用训练集的参数标准化测试集
    "X_test_norm = None  # 替换为你的代码"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "**练习 4.3**：实现完整的逻辑回归训练"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 实现完整的逻辑回归训练函数\n",
    "\n",
    "def train_logistic_regression(X, y, learning_rate=0.01, epochs=1000, verbose=True):\n",
    "    \"\"\"\n",
    "    逻辑回归训练\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # 初始化参数\n",
    "    w = np.zeros(n)\n",
    "    b = 0\n",
    "    \n",
    "    # 记录损失\n",
    "    costs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 1. 计算当前损失\n",
    "        cost = None  # 替换为你的代码\n",
    "        costs.append(cost)\n",
    "        \n",
    "        # 2. 计算梯度\n",
    "        dw, db = None  # 替换为你的代码\n",
    "        \n",
    "        # 3. 更新参数\n",
    "        w = None  # 替换为你的代码\n",
    "        b = None  # 替换为你的代码\n",
    "        \n",
    "        if verbose and epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {cost:.4f}\")\n",
    "    \n",
    "    return w, b, costs\n",
    "\n",
    "# 训练模型\n",
    "w_manual, b_manual, costs_manual = train_logistic_regression(\n",
    "    X_train_norm, y_train, learning_rate=0.1, epochs=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "**练习 4.4**：预测函数实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 实现预测函数\n",
    "\n",
    "def predict_proba(X, w, b):\n",
    "    \"\"\"\n",
    "    预测概率\n",
    "    \n",
    "    Args:\n",
    "        X: 特征数据\n",
    "        w: 权重\n",
    "        b: 偏置\n",
    "    \n",
    "    Returns:\n",
    "        概率值\n",
    "    \"\"\"\n",
    "    z = None  # 替换为你的代码\n",
    "    probabilities = None  # 替换为你的代码\n",
    "    return probabilities\n",
    "\n",
    "def predict(X, w, b, threshold=0.5):\n",
    "    \"\"\"\n",
    "    预测类别\n",
    "    \n",
    "    Args:\n",
    "        X: 特征数据\n",
    "        w: 权重\n",
    "        b: 偏置\n",
    "        threshold: 决策阈值\n",
    "    \n",
    "    Returns:\n",
    "        预测类别（0 或 1）\n",
    "    \"\"\"\n",
    "    probs = predict_proba(X, w, b)\n",
    "    predictions = (probs >= threshold).astype(int)\n",
    "    return predictions\n",
    "\n",
    # 测试预测\n    "y_pred_proba = predict_proba(X_test_norm, w_manual, b_manual)\n",
    "y_pred_manual = predict(X_test_norm, w_manual, b_manual)\n",
    "\n",
    "print(\"预测测试:\")\n",
    "print(f\"前5个样本的真实标签: {y_test[:5]}\")\n",
    "print(f\"前5个样本的预测概率: {y_pred_proba[:5]:.4f}\")\n",
    "print(f\"前5个样本的预测类别: {y_pred_manual[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "---\n",
    "## Part 5: scikit-learn 实现"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "**练习 5.1**：使用 sklearn 的逻辑回归"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 使用 sklearn 的 LogisticRegression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1. 创建并训练模型\n",
    "model_sklearn = None  # 替换为你的代码\n",
    "\n",
    "# 2. 获取模型参数\n",
    "w_sklearn = None  # 替换为你的代码\n",
    "b_sklearn = None  # 替换为你的代码\n",
    "\n",
    "print(\"sklearn 训练结果:\")\n",
    "print(f\"权重: {w_sklearn}\")\n",
    "print(f\"偏置: {b_sklearn:.4f}\")\n",
    "\n",
    "# 3. 进行预测\n",
    "y_pred_sklearn = None  # 替换为你的代码\n    "\n",
    "# 4. 计算预测概率\n",
    "y_pred_proba_sklearn = None  # 替换为你的代码\n    "\n",
    "print(\"\\n预测测试:\")\n",
    "print(f\"前5个样本的预测概率: {y_pred_proba_sklearn[:5][:, 1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "**练习 5.2**：比较手动实现和 sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 比较两种实现的参数和性能\n",
    "\n",
    "# 计算参数差异\n",
    "weight_diff = None  # 替换为你的代码\n",
    "bias_diff = None  # 替换为你的代码\n",
    "\n",
    "print(\"参数对比:\")\n",
    "print(f\"权重差异: {weight_diff:.6f}\")\n",
    "print(f\"偏置差异: {bias_diff:.6f}\")\n",
    "\n",
    "# 比较预测结果\n",
    "pred_diff = np.sum(y_pred_manual != y_pred_sklearn)\n",
    "print(f\"\\n预测差异样本数: {pred_diff} / {len(y_test)}\")\n",
    "print(\"说明: 由于优化算法和收敛程度不同，结果可能略有差异\")"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "---\n",
    "## Part 6: 模型评估"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "**练习 6.1**：计算分类指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 手动计算分类评估指标\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    手动计算分类评估指标\n",
    "    \"\"\"\n",
    "    # 计算混淆矩阵\n",
    "    TP = None  # 真正例\n",
    "    TN = None  # 真负例\n",
    "    FP = None  # 假正例\n",
    "    FN = None  # 假负例\n",
    "    \n",
    "    # 计算各项指标\n",
    "    accuracy = None  # 准确率\n",
    "    precision = None  # 精确率\n",
    "    recall = None  # 召回率\n",
    "    f1 = None  # F1分数\n",
    "    \n",
    "    return {\n",
    "        'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1\n",
    "    }\n",
    "\n",
    # 评估手动实现的模型\n    "metrics_manual = calculate_metrics(y_test, y_pred_manual)\n",
    "\n",
    # 评估 sklearn 模型\n",
    "metrics_sklearn = calculate_metrics(y_test, y_pred_sklearn)\n",
    "\n",
    "print(\"模型评估对比:\")\n",
    "print(\"\\n手动实现:\")\n",
    "for metric, value in metrics_manual.items():\n",
    "    if metric in ['TP', 'TN', 'FP', 'FN']:\n",
    "        print(f\"  {metric}: {value}\")\n",
    "    else:\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nsklearn:\")\n",
    "for metric, value in metrics_sklearn.items():\n",
    "    if metric in ['TP', 'TN', 'FP', 'FN']:\n",
    "        print(f\"  {metric}: {value}\")\n",
    "    else:\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "**练习 6.2**：使用 sklearn 的评估函数验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 使用 sklearn 的评估函数\n",
    "\n",
    "print(\"sklearn 官方评估结果:\")\n",
    "print(\"\\n混淆矩阵:\")\n",
    "print(confusion_matrix(y_test, y_pred_sklearn))\n",
    "\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(y_test, y_pred_sklearn, \n",
    "                           target_names=['malignant', 'benign']))"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "---\n",
    "## Part 7: 可视化决策边界"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "**练习 7.1**：绘制决策边界"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 绘制决策边界和数据点\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# 1. 创建网格点用于绘制决策边界\n",
    "x_min, x_max = X_train_norm[:, 0].min() - 1, X_train_norm[:, 0].max() + 1\n",
    "y_min, y_max = X_train_norm[:, 1].min() - 1, X_train_norm[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "\n",
    "# 2. 预测网格点的概率\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = predict_proba(grid_points, w_manual, b_manual)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# 3. 绘制决策边界\n",
    "contour = plt.contourf(xx, yy, Z, levels=50, cmap='RdYlBu', alpha=0.3)\n",
    "plt.colorbar(contour, label='预测概率（benign）')\n",
    "\n",
    "# 4. 绘制数据点\n",
    "colors = ['red' if label == 0 else 'blue' for label in y_train]\n",
    "plt.scatter(X_train_norm[:, 0], X_train_norm[:, 1], \n",
    "            c=colors, alpha=0.8, s=50,\n",
    "            edgecolors='black', linewidth=1,\n",
    "            label=['malignant', 'benign'])\n",
    "\n",
    plt.xlabel('mean radius (标准化)', fontsize=12)\n",
    "plt.ylabel('mean texture (标准化)', fontsize=12)\n",
    "plt.title('逻辑回归决策边界', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "**练习 7.2**：绘制 ROC 曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 绘制 ROC 曲线\n",
    "\n",
    "def plot_roc_curve(y_true, y_probabilities, model_name=\"\"):\n",
    "    \"\"\"\n",
    "    绘制 ROC 曲线\n",
    "    \"\"\"\n",
    "    # 生成不同的阈值\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    \n",
    "    # 计算每个阈值下的 TPR 和 FPR\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # 根据阈值预测类别\n",
    "        y_pred = (y_probabilities >= threshold).astype(int)\n",
    "        \n",
    "        # 计算混淆矩阵\n",
    "        TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "        FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "        FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "        \n",
    "        # 计算 TPR 和 FPR\n",
    "        tpr = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "        \n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "    \n",
    "    # 计算 AUC\n",
    "    auc_score = np.trapz(tpr_list, fpr_list)\n",
    "    \n",
    "    # 绘制 ROC 曲线\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr_list, tpr_list, label=f'{model_name} (AUC = {auc_score:.3f})', linewidth=2)\n",
    "    \n",
    "    # 绘制对角线（随机分类器）\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='随机分类器', linewidth=1)\n",
    "    \n",
    "    plt.xlabel('假正率 (FPR)', fontsize=12)\n",
    "    plt.ylabel('真正率 (TPR/Recall)', fontsize=12)\n",
    "    plt.title('ROC 曲线', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=':', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    # 绘制 ROC 曲线（使用 sklearn 的预测概率）
    "plot_roc_curve(y_test, y_pred_proba_sklearn[:, 1], \"sklearn 逻辑回归\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "---\n",
    "## Part 8: 挑战练习"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "**挑战 8.1**：使用所有特征进行分类"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 使用所有特征训练模型\n",
    "\n",
    "# 1. 使用所有特征\n",
    "X_all = X\n",
    "\n",
    "# 2. 划分训练集和测试集\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(\n",
    "    X_all, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 3. 标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_all_scaled = None  # 替换为你的代码\n",
    "X_test_all_scaled = None  # 替换为你的代码\n",
    "\n",
    "# 4. 使用 sklearn 训练模型\n",
    "model_all = None  # 替换为你的代码\n",
    "model_all.fit(X_train_all_scaled, y_train_all)\n",
    "\n",
    "# 5. 评估模型\n",
    "y_pred_all = None  # 替换为你的代码\n",
    "accuracy_all = None  # 替换为你的代码\n",
    "\n",
    "print(\"使用所有特征的结果:\")\n",
    "print(f\"测试集准确率: {accuracy_all:.4f}\")\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(y_test_all, y_pred_all, \n",
    "                           target_names=['malignant', 'benign']))"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "**挑战 8.2**：实现正则化"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# ===== 学生代码 =====\n",
    "# TODO: 实现带 L2 正则化的逻辑回归\n",
    "\n",
    "def train_logistic_regression_l2(X, y, learning_rate=0.01, epochs=1000, \n",
    "                               lambda_reg=0.1, verbose=True):\n",
    "    \"\"\"\n",
    "    带 L2 正则化的逻辑回归\n",
    "    J = BCE_loss + (lambda_reg/2) * ||w||^2\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # 初始化参数\n",
    "    w = np.zeros(n)\n",
    "    b = 0\n",
    "    \n",
    "    # 记录损失\n",
    "    costs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 1. 计算当前损失（包含正则化项）\n",
    "        z = np.dot(X, w) + b\n",
    "        y_pred = sigmoid(z)\n",
    "        \n",
    "        # 基础损失\n",
    "        epsilon = 1e-15\n",
    "        y_pred_clipped = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        loss = -(1/m) * np.sum(y * np.log(y_pred_clipped) + (1 - y) * np.log(1 - y_pred_clipped))\n",
    "        \n",
    "        # L2 正则化项（不包括偏置）\n",
    "        regularization = (lambda_reg / 2) * np.sum(w ** 2)\n",
    "        total_loss = loss + regularization\n",
    "        costs.append(total_loss)\n",
    "        \n",
    "        # 2. 计算梯度（加入正则化项）\n",
    "        dw = (1/m) * np.dot(X.T, (y_pred - y)) + lambda_reg * w\n",
    "        db = (1/m) * np.sum(y_pred - y)\n",
    "        \n",
    "        # 3. 更新参数\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        if verbose and epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {total_loss:.4f}\")\n",
    "    \n",
    "    return w, b, costs\n",
    "\n",
    # 训练带正则化的模型\n",
    "w_l2, b_l2, costs_l2 = train_logistic_regression_l2(\n",
    "    X_train_all_scaled, y_train_all, learning_rate=0.1, epochs=1000, lambda_reg=0.1\n",
    ")\n",
    "\n",
    # 评估带正则化的模型\n",
    "y_pred_l2 = predict(X_test_all_scaled, w_l2, b_l2)\n",
    "accuracy_l2 = accuracy_score(y_test_all, y_pred_l2)\n",
    "\n",
    "print(\"\\n带 L2 正则化的结果:\")\n",
    "print(f\"测试集准确率: {accuracy_l2:.4f}\")\n",
    "print(\"\\n与无正则化的比较:\")\n",
    "print(f\"无正则化准确率: {accuracy_all:.4f}\")\n",
    "print(f\"L2 正则化准确率: {accuracy_l2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "---\n",
    "## 实验总结\n",
    "\n",
    "恭喜你完成了逻辑回归实践！通过本实验，你应该掌握了：\n",
    "\n",
    "1. ✓ Sigmoid 函数及其在分类中的作用\n",
    "2. ✓ 交叉熵损失函数的原理和实现\n",
    "3. ✓ 手动实现逻辑回归的梯度下降\n",
    "4. ✓ 使用 scikit-learn 快速实现逻辑回归\n",
    "5. ✓ 分类评估指标：准确率、精确率、召回率、F1\n",
    "6. ✓ 可视化决策边界和 ROC 曲线\n",
    "7. ✓ 使用所有特征提高分类性能\n",
    "8. ✓ L2 正则化防止过拟合\n",
    "\n",
    "逻辑回归是二分类问题的基准算法，理解它的原理和实现对于学习更复杂的分类算法至关重要。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}