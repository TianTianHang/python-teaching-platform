{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: K 近邻算法 (KNN) 实践 - 参考答案\n",
    "\n",
    "在本实验中，我们使用 Digits 数据集来学习 K 近邻算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: 数据加载与探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"库导入成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "print(\"数据集信息:\")\n",
    "print(f\"样本数量: {X.shape[0]}\")\n",
    "print(f\"特征数量: {X.shape[1]}\")\n",
    "print(f\"类别数量: {len(np.unique(y))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 可视化前 20 个数字\n",
    "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(20):\n",
    "    axes[i].imshow(digits.images[i], cmap='gray')\n",
    "    axes[i].set_title(f'标签: {y[i]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Digits 数据集 - 前20个样本', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 数据集统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 统计每个数字的样本数量\n",
    "label_counts = np.bincount(y)\n",
    "\n",
    "print(\"每个数字的样本数量:\")\n",
    "for digit, count in enumerate(label_counts):\n",
    "    print(f\"  数字 {digit}: {count} 个样本\")\n",
    "\n",
    "# 可视化类别分布\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(10), label_counts, color=plt.cm.tab10.colors[:10])\n",
    "plt.xlabel('数字')\n",
    "plt.ylabel('样本数量')\n",
    "plt.title('Digits 数据集 - 类别分布')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 数据预处理与划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "X_normalized = X / 16.0\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_normalized, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape}\")\n",
    "print(f\"测试集大小: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: 距离度量实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 欧氏距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    计算欧氏距离\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "# 测试\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7, 8])\n",
    "dist = euclidean_distance(a, b)\n",
    "print(f\"欧氏距离测试: d({a}, {b}) = {dist:.4f}\")\n",
    "# 预期输出: 8.0 (sqrt(16+16+16+16) = sqrt(64) = 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 曼哈顿距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def manhattan_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    计算曼哈顿距离\n",
    "    \"\"\"\n",
    "    return np.sum(np.abs(x1 - x2))\n",
    "\n",
    "# 测试\n",
    "dist_m = manhattan_distance(a, b)\n",
    "print(f\"曼哈顿距离测试: d({a}, {b}) = {dist_m:.4f}\")\n",
    "# 预期输出: 16.0 (|1-5|+|2-6|+|3-7|+|4-8| = 4+4+4+4 = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 批量距离计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def compute_distances(X_train, x_test, metric='euclidean'):\n",
    "    \"\"\"\n",
    "    批量计算距离\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    \n",
    "    if metric == 'euclidean':\n",
    "        dist_func = euclidean_distance\n",
    "    elif metric == 'manhattan':\n",
    "        dist_func = manhattan_distance\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的度量: {metric}\")\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        dist = dist_func(x_test, X_train[i])\n",
    "        distances.append(dist)\n",
    "    \n",
    "    return np.array(distances)\n",
    "\n",
    "# 测试\n",
    "x_sample = X_test[0]\n",
    "dists = compute_distances(X_train, x_sample, metric='euclidean')\n",
    "print(f\"距离范围: [{dists.min():.4f}, {dists.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: 手动实现 KNN 分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 实现预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def knn_predict(X_train, y_train, x_test, k=5):\n",
    "    \"\"\"\n",
    "    KNN 预测函数\n",
    "    \"\"\"\n",
    "    # 1. 计算距离\n",
    "    distances = compute_distances(X_train, x_test, metric='euclidean')\n",
    "    \n",
    "    # 2. 获取最近的 k 个样本索引\n",
    "    k_indices = np.argsort(distances)[:k]\n",
    "    \n",
    "    # 3. 获取 k 个最近邻的标签\n",
    "    k_nearest_labels = y_train[k_indices]\n",
    "    \n",
    "    # 4. 多数投票\n",
    "    counter = Counter(k_nearest_labels)\n",
    "    prediction = counter.most_common(1)[0][0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# 测试\n",
    "x_test_sample = X_test[0]\n",
    "true_label = y_test[0]\n",
    "pred_label = knn_predict(X_train, y_train, x_test_sample, k=5)\n",
    "\n",
    "print(f\"真实标签: {true_label}, 预测标签: {pred_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 批量预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def knn_predict_batch(X_train, y_train, X_test, k=5):\n",
    "    \"\"\"\n",
    "    批量预测\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        pred = knn_predict(X_train, y_train, X_test[i], k)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "# 测试（只取前10个样本以节省时间）\n",
    "y_pred_manual = knn_predict_batch(X_train, y_train, X_test[:10], k=5)\n",
    "accuracy = np.mean(y_pred_manual == y_test[:10])\n",
    "print(f\"手动实现的 KNN 准确率 (前10个样本): {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: 使用 scikit-learn 的 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 创建 KNN 分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 创建 KNN 分类器\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 训练模型\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "train_acc = knn.score(X_train, y_train)\n",
    "test_acc = knn.score(X_test, y_test)\n",
    "\n",
    "print(f\"KNN 分类器 (K=5):\")\n",
    "print(f\"  训练集准确率: {train_acc:.4f}\")\n",
    "print(f\"  测试集准确率: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 寻找最优 K 值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 尝试不同的 K 值\n",
    "k_values = list(range(1, 31, 2))\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    train_scores.append(knn.score(X_train, y_train))\n",
    "    test_scores.append(knn.score(X_test, y_test))\n",
    "\n",
    "# 找到最佳 K 值\n",
    "best_k = k_values[np.argmax(test_scores)]\n",
    "best_score = max(test_scores)\n",
    "\n",
    "print(f\"最佳 K 值: {best_k}\")\n",
    "print(f\"最佳测试集准确率: {best_score:.4f}\")\n",
    "\n",
    "# 绘制结果\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_values, train_scores, 'o-', label='训练集准确率')\n",
    "plt.plot(k_values, test_scores, 's-', label='测试集准确率')\n",
    "plt.axvline(x=best_k, color='green', linestyle='--', label=f'最佳 K={best_k}')\n",
    "plt.xlabel('K 值')\n",
    "plt.ylabel('准确率')\n",
    "plt.title('K 值对模型性能的影响')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 加权 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 创建两个 KNN 模型\n",
    "knn_uniform = KNeighborsClassifier(n_neighbors=best_k, weights='uniform')\n",
    "knn_distance = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
    "\n",
    "# 训练\n",
    "knn_uniform.fit(X_train, y_train)\n",
    "knn_distance.fit(X_train, y_train)\n",
    "\n",
    "# 评估\n",
    "uniform_acc = knn_uniform.score(X_test, y_test)\n",
    "distance_acc = knn_distance.score(X_test, y_test)\n",
    "\n",
    "print(\"权重策略比较:\")\n",
    "print(f\"  均匀权重: {uniform_acc:.4f}\")\n",
    "print(f\"  距离权重: {distance_acc:.4f}\")\n",
    "\n",
    # 创建图表比较不同权重策略
    k_range = range(1, 21)
    uniform_scores = []
    distance_scores = []

    for k in k_range:
        knn_u = KNeighborsClassifier(n_neighbors=k, weights='uniform')
        knn_d = KNeighborsClassifier(n_neighbors=k, weights='distance')

        knn_u.fit(X_train, y_train)
        knn_d.fit(X_train, y_train)

        uniform_scores.append(knn_u.score(X_test, y_test))
        distance_scores.append(knn_d.score(X_test, y_test))

    plt.figure(figsize=(10, 5))
    plt.plot(k_range, uniform_scores, 'o-', label='均匀权重')
    plt.plot(k_range, distance_scores, 's-', label='距离权重')
    plt.xlabel('K 值')
    plt.ylabel('准确率')
    plt.title('不同权重策略的性能比较')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: 模型评估与可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 使用最佳模型进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 使用最佳参数创建模型\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
    "\n",
    "# 训练并预测\n",
    "best_knn.fit(X_train, y_train)\n",
    "y_pred_best = best_knn.predict(X_test)\n",
    "\n",
    "# 显示分类报告\n",
    "print(\"分类报告:\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "print(f\"测试集准确率: {accuracy_score(y_test, y_pred_best):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 混淆矩阵可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.xlabel('预测类别')\n",
    "plt.ylabel('真实类别')\n",
    "plt.title('混淆矩阵 - 手写数字识别')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 可视化预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 找出预测正确和错误的样本\n",
    "correct_indices = np.where(y_pred_best == y_test)[0]\n",
    "incorrect_indices = np.where(y_pred_best != y_test)[0]\n",
    "\n",
    "print(f\"预测正确数量: {len(correct_indices)}\")\n",
    "print(f\"预测错误数量: {len(incorrect_indices)}\")\n",
    "\n",
    "# 可视化一些预测结果\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "\n",
    "# 第一行: 预测正确的样本\n",
    "for i in range(5):\n",
    "    idx = correct_indices[i]\n",
    "    img = X_test[idx].reshape(8, 8)\n",
    "    axes[0, i].imshow(img, cmap='gray')\n",
    "    axes[0, i].set_title(f'真实:{y_test[idx]}, 预测:{y_pred_best[idx]}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# 第二行: 预测错误的样本\n",
    "for i in range(5):\n",
    "    if i < len(incorrect_indices):\n",
    "        idx = incorrect_indices[i]\n",
    "        img = X_test[idx].reshape(8, 8)\n",
    "        axes[1, i].imshow(img, cmap='gray')\n",
    "        axes[1, i].set_title(f'真实:{y_test[idx]}, 预测:{y_pred_best[idx]}', color='red')\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('预测正确', fontsize=12)\n",
    "axes[1, 0].set_ylabel('预测错误', fontsize=12)\n",
    "plt.suptitle('KNN 预测结果示例', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: 挑战练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 5 折交叉验证\n",
    "cv_scores = cross_val_score(\n",
    "    best_knn, \n",
    "    X_normalized, \n",
    "    y, \n",
    "    cv=5\n",
    ")\n",
    "\n",
    "print(\"5 折交叉验证结果:\")\n",
    "print(f\"每折分数: {cv_scores}\")\n",
    "print(f\"平均分数: {cv_scores.mean():.4f}\")\n",
    "print(f\"标准差: {cv_scores.std():.4f}\")\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(1, 6), cv_scores, alpha=0.7, edgecolor='black')\n",
    "plt.axhline(y=cv_scores.mean(), color='red', linestyle='--',\n",
    "            label=f'平均分: {cv_scores.mean():.4f}')\n",
    "plt.xlabel('折数')\n",
    "plt.ylabel('准确率')\n",
    "plt.title('5 折交叉验证结果')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 决策边界可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# PCA 降维\n",
    "pca = PCA(n_components=2)\n",
    "X_train_2d = pca.fit_transform(X_train)\n",
    "X_test_2d = pca.transform(X_test)\n",
    "\n",
    "print(f\"PCA 保留的方差比例: {np.sum(pca.explained_variance_ratio_):.4f}\")\n",
    "\n",
    "# 在 2D 数据上训练 KNN\n",
    "knn_2d = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_2d.fit(X_train_2d, y_train)\n",
    "\n",
    "# 创建网格\n",
    "x_min, x_max = X_train_2d[:, 0].min() - 1, X_train_2d[:, 0].max() + 1\n",
    "y_min, y_max = X_train_2d[:, 1].min() - 1, X_train_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# 预测网格\n",
    "Z = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# 绘制决策边界\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 左图: 训练集\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train,\n",
    "                       cmap='tab10', alpha=0.6, s=30)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='tab10')\n",
    "plt.xlabel('主成分 1')\n",
    "plt.ylabel('主成分 2')\n",
    "plt.title('训练集 - PCA 降维后的决策边界')\n",
    "plt.colorbar(scatter, label='数字')\n",
    "\n",
    "# 右图: 测试集\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(X_test_2d[:, 0], X_test_2d[:, 1], c=y_test,\n",
    "                       cmap='tab10', alpha=0.6, s=30)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='tab10')\n",
    "plt.xlabel('主成分 1')\n",
    "plt.ylabel('主成分 2')\n",
    "plt.title('测试集 - PCA 降维后的决策边界')\n",
    "plt.colorbar(scatter, label='数字')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 性能分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "import time\n",
    "\n",
    "# 测试不同 K 值的预测时间\n",
    "k_values = [1, 5, 11, 21, 31, 51]\n",
    "prediction_times = []\n",
    "\n",
    "print(\"测量不同 K 值的预测时间...\\n\")\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # 测量预测时间（对测试集进行多次测量取平均）\n",
    "    start = time.time()\n",
    "    knn.predict(X_test)\n",
    "    end = time.time()\n",
    "    \n",
    "    elapsed = end - start\n",
    "    prediction_times.append(elapsed)\n",
    "    print(f\"K={k:2d}: 预测时间 = {elapsed:.4f} 秒\")\n",
    "\n",
    "# 绘制结果\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_values, prediction_times, 'o-', linewidth=2)\n",
    "plt.xlabel('K 值')\n",
    "plt.ylabel('预测时间 (秒)')\n",
    "plt.title('K 值对预测时间的影响')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n结论:\")\n",
    "print(\"- KNN 的预测时间随 K 值增加略有增加\")\n",
    "print(\"- KNN 的主要开销是距离计算，与 K 值关系不大\")\n",
    "print(\"- scikit-learn 内部使用 KD 树或 Ball 树优化搜索效率\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 关键知识点总结\n",
    "\n",
    "1. **KNN 原理**：基于实例的学习，无需训练过程，直接存储训练数据\n",
    "2. **距离度量**：欧氏距离是最常用的，曼哈顿距离对异常值更鲁棒\n",
    "3. **K 值选择**：通过交叉验证寻找最优 K，通常 K 是奇数\n",
    "4. **权重策略**：距离权重通常比均匀权重效果好\n",
    "5. **特征缩放**：KNN 对特征尺度敏感，必须进行归一化\n",
    "6. **计算复杂度**：预测时需要计算所有样本的距离，时间复杂度 O(n)\n",
    "\n",
    "### KNN 的优缺点\n",
    "\n",
    "**优点**：\n",
    "- 简单直观，易于理解\n",
    "- 不需要训练过程\n",
    "- 对异常值不敏感（K > 1 时）\n",
    "- 天然支持多分类\n",
    "\n",
    "**缺点**：\n",
    "- 预测时计算成本高\n",
    "- 需要存储所有训练数据\n",
    "- 高维数据容易受到维度灾难影响\n",
    "- 对数据不平衡敏感\n",
    "\n",
    "### 最佳实践\n",
    "\n",
    "- 使用特征缩放（标准化或归一化）\n",
    "- 交叉验证选择最优 K 值\n",
    "- 尝试不同的距离度量\n",
    "- 考虑使用距离权重\n",
    "- 对于大数据集，考虑使用近似最近邻算法"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
