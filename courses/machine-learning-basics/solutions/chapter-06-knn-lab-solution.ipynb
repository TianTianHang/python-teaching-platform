{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: K 近邻算法 (KNN) 实践\n",
    "\n",
    "## 实验概述\n",
    "\n",
    "在本实验中，你将使用 **Digits 数据集**（手写数字识别）来学习 K 近邻算法的实现和应用。Digits 数据集包含 1797 个 8x8 像素的手写数字图像，每个图像对应 0-9 中的一个数字。\n",
    "\n",
    "### 实验目标\n",
    "\n",
    "1. 理解 KNN 算法的基本原理\n",
    "2. 实现欧氏距离计算\n",
    "3. 手动实现 KNN 分类器\n",
    "4. 使用 scikit-learn 的 KNN 模型\n",
    "5. 找到最优的 K 值\n",
    "6. 可视化决策边界和混淆矩阵\n",
    "\n",
    "### 数据集信息\n",
    "\n",
    "- **样本数量**: 1797\n",
    "- **特征数量**: 64 (8x8 像素)\n",
    "- **类别数量**: 10 (数字 0-9)\n",
    "- **特征**: 每个特征的值是 0-16 之间的灰度值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: 数据加载与探索\n",
    "\n",
    "### 1.1 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"库导入成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 加载 Digits 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 加载数据集\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "print(\"数据集信息:\")\n",
    "print(f\"样本数量: {X.shape[0]}\")\n",
    "print(f\"特征数量: {X.shape[1]}\")\n",
    "print(f\"图像尺寸: 8x8\")\n",
    "print(f\"类别数量: {len(np.unique(y))}\")\n",
    "print(f\"\\n类别: {np.unique(y)}\")\n",
    "print(f\"\\n特征值范围: [{X.min():.1f}, {X.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 可视化手写数字图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 可视化前 20 个数字图像\n",
    "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(20):\n",
    "    axes[i].imshow(digits.images[i], cmap='gray')\n",
    "    axes[i].set_title(f'标签: {y[i]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Digits 数据集 - 前20个样本', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 数据集统计\n",
    "\n",
    "**任务**: 统计每个数字的样本数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 统计每个数字的样本数量\n",
    "label_counts = np.bincount(y)\n",
    "\n",
    "print(\"每个数字的样本数量:\")\n",
    "for digit, count in enumerate(label_counts):\n",
    "    print(f\"  数字 {digit}: {count} 个样本\")\n",
    "\n",
    "# 可视化类别分布\n",
    "plt.figure(figsize=(10, 5))\n",
    "# 绘制柱状图显示每个数字的样本数量\n",
    "bars = plt.bar(range(10), label_counts, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('数字')\n",
    "plt.ylabel('样本数量')\n",
    "plt.title('Digits 数据集 - 类别分布')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    # 在柱子上显示数量\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height)}',\n",
    "             ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 数据预处理与划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 特征归一化 (0-1 范围)\n",
    "X_normalized = X / 16.0  # 像素值范围是 0-16\n",
    "\n",
    "# 划分数据集 (80% 训练, 20% 测试)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_normalized, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape}\")\n",
    "print(f\"测试集大小: {X_test.shape}\")\n",
    "print(f\"\\n特征值范围 (归一化后): [{X_normalized.min():.1f}, {X_normalized.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: 距离度量实现\n",
    "\n",
    "### 2.1 欧氏距离\n",
    "\n",
    "**任务**: 实现欧氏距离函数 $d(x, y) = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    计算两个向量之间的欧氏距离\n",
    "    \n",
    "    参数:\n",
    "    x1: 第一个向量 (n_features,)\n",
    "    x2: 第二个向量 (n_features,)\n",
    "    \n",
    "    返回:\n",
    "    欧氏距离\n",
    "    \"\"\"\n",
    "    # 实现欧氏距离计算\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "# 测试欧氏距离函数\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7, 8])\n",
    "dist = euclidean_distance(a, b)\n",
    "print(f\"欧氏距离测试: d({a}, {b}) = {dist:.4f}\")\n",
    "# 预期输出: 8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 曼哈顿距离\n",
    "\n",
    "**任务**: 实现曼哈顿距离函数 $d(x, y) = \\sum_{i=1}^{n}|x_i - y_i|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def manhattan_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    计算两个向量之间的曼哈顿距离\n",
    "    \n",
    "    参数:\n",
    "    x1: 第一个向量\n",
    "    x2: 第二个向量\n",
    "    \n",
    "    返回:\n",
    "    曼哈顿距离\n",
    "    \"\"\"\n",
    "    # 实现曼哈顿距离计算\n",
    "    return np.sum(np.abs(x1 - x2))\n",
    "\n",
    "# 测试曼哈顿距离函数\n",
    "dist_m = manhattan_distance(a, b)\n",
    "print(f\"曼哈顿距离测试: d({a}, {b}) = {dist_m:.4f}\")\n",
    "# 预期输出: 16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 批量距离计算\n",
    "\n",
    "**任务**: 计算一个样本到所有训练样本的距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def compute_distances(X_train, x_test, metric='euclidean'):\n",
    "    \"\"\"\n",
    "    计算测试样本到所有训练样本的距离\n",
    "    \n",
    "    参数:\n",
    "    X_train: 训练集 (n_samples, n_features)\n",
    "    x_test: 测试样本 (n_features,)\n",
    "    metric: 距离度量 ('euclidean' 或 'manhattan')\n",
    "    \n",
    "    返回:\n",
    "    距离数组 (n_samples,)\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    \n",
    "    # 遍历训练集，计算每个样本到测试样本的距离\n",
    "    if metric == 'euclidean':\n",
    "        for x_train in X_train:\n",
    "            dist = euclidean_distance(x_train, x_test)\n",
    "            distances.append(dist)\n",
    "    elif metric == 'manhattan':\n",
    "        for x_train in X_train:\n",
    "            dist = manhattan_distance(x_train, x_test)\n",
    "            distances.append(dist)\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的度量方法: {metric}\")\n",
    "    \n",
    "    return np.array(distances)\n",
    "\n",
    "# 测试\n",
    "x_sample = X_test[0]\n",
    "dists = compute_distances(X_train, x_sample, metric='euclidean')\n",
    "print(f\"测试样本到训练集的距离 (前10个): {dists[:10]}\")\n",
    "print(f\"最小距离: {dists.min():.4f}\")\n",
    "print(f\"最大距离: {dists.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 距离度量比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 比较不同距离度量\n",
    "sample_idx = 5  # 选择一个样本进行测试\n",
    "x_sample = X_test[sample_idx]\n",
    "true_label = y_test[sample_idx]\n",
    "\n",
    "# 计算两种距离\n",
    "euclidean_dists = compute_distances(X_train, x_sample, 'euclidean')\n",
    "manhattan_dists = compute_distances(X_train, x_sample, 'manhattan')\n",
    "\n",
    # 找到最近的邻居\n",
    "euclidean_k_idx = np.argmin(euclidean_dists)\n",
    "manhattan_k_idx = np.argmin(manhattan_dists)\n",
    "\n",
    print(f\"测试样本 {true_label} 的最近邻居:\")\n",
    "print(f\"欧氏距离: 训练样本 {y_train[euclidean_k_idx]} (距离: {euclidean_dists[euclidean_k_idx]:.4f})\")\n",
    "print(f\"曼哈顿距离: 训练样本 {y_train[manhattan_k_idx]} (距离: {manhattan_dists[manhattan_k_idx]:.4f})\")\n",
    "\n",
    # 可视化\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(range(len(euclidean_dists)), euclidean_dists, alpha=0.5, s=2)\n",
    "plt.scatter(euclidean_k_idx, euclidean_dists[euclidean_k_idx], color='red', s=100, label='最近邻')\n",
    "plt.xlabel('训练样本索引')\n",
    "plt.ylabel('欧氏距离')\n",
    "plt.title(f'测试样本 {true_label} 到所有训练样本的距离')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(range(len(manhattan_dists)), manhattan_dists, alpha=0.5, s=2, color='orange')\n",
    "plt.scatter(manhattan_k_idx, manhattan_dists[manhattan_k_idx], color='red', s=100, label='最近邻')\n",
    "plt.xlabel('训练样本索引')\n",
    "plt.ylabel('曼哈顿距离')\n",
    "plt.title(f'测试样本 {true_label} 到所有训练样本的距离')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: 手动实现 KNN 分类器\n",
    "\n",
    "### 3.1 实现预测函数\n",
    "\n",
    "**任务**: 实现 KNN 预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def knn_predict(X_train, y_train, x_test, k=5):\n",
    "    \"\"\"\n",
    "    KNN 分类预测\n",
    "    \n",
    "    参数:\n",
    "    X_train: 训练集特征\n",
    "    y_train: 训练集标签\n",
    "    x_test: 测试样本\n",
    "    k: 邻居数量\n",
    "    \n",
    "    返回:\n",
    "    预测类别\n",
    "    \"\"\"\n",
    "    # 计算测试样本到所有训练样本的距离\n",
    "    distances = compute_distances(X_train, x_test)\n",
    "    \n",
    "    # 获取距离最近的 k 个样本的索引\n",
    "    k_indices = np.argsort(distances)[:k]\n",
    "    \n",
    "    # 获取 k 个最近邻的标签\n",
    "    k_nearest_labels = y_train[k_indices]\n",
    "    \n",
    "    # 多数投票，返回最常见的类别\n",
    "    label_counts = Counter(k_nearest_labels)\n",
    "    prediction = label_counts.most_common(1)[0][0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# 测试 KNN 预测\n",
    "x_test_sample = X_test[0]\n",
    "true_label = y_test[0]\n",
    "pred_label = knn_predict(X_train, y_train, x_test_sample, k=5)\n",
    "\n",
    "print(f\"真实标签: {true_label}\")\n",
    "print(f\"预测标签: {pred_label}\")\n",
    "print(f\"预测{'正确' if true_label == pred_label else '错误'}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 批量预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def knn_predict_batch(X_train, y_train, X_test, k=5):\n",
    "    \"\"\"\n",
    "    对测试集进行批量预测\n",
    "    \n",
    "    参数:\n",
    "    X_train: 训练集特征\n",
    "    y_train: 训练集标签\n",
    "    X_test: 测试集特征\n",
    "    k: 邻居数量\n",
    "    \n",
    "    返回:\n",
    "    预测标签数组\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    # 遍历测试集，对每个样本进行预测\n",
    "    for x_test in X_test:\n",
    "        pred = knn_predict(X_train, y_train, x_test, k)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    # 在小测试集上测试（只取前20个样本加快速度）\n",
    "print(\"在测试集子集上进行预测（前20个样本）...\")\n",
    "y_pred_manual = knn_predict_batch(X_train, y_train, X_test[:20], k=5)\n",
    "\n",
    "accuracy = np.mean(y_pred_manual == y_test[:20])\n",
    "print(f\"手动实现的 KNN 准确率: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 性能测试 - 不同K值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 测试不同 K 值的性能（使用较小的样本集）\n",
    "sample_size = 50  # 只取50个测试样本来加快速度\n",
    "test_k_values = [1, 3, 5, 7, 9]\n",
    "test_accuracies = []\n",
    "\n",
    "print(\"测试不同 K 值的性能...\")\n",
    "for k in test_k_values:\n",
    "    y_pred = knn_predict_batch(X_train, y_train, X_test[:sample_size], k=k)\n",
    "    acc = np.mean(y_pred == y_test[:sample_size])\n",
    "    test_accuracies.append(acc)\n",
    "    print(f\"K={k}: 准确率 = {acc:.4f}\")\n",
    "\n",
    # 可视化\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(test_k_values, test_accuracies, 'o-', linewidth=2)\n",
    "plt.xlabel('K 值')\n",
    "plt.ylabel('准确率')\n",
    "plt.title('不同 K 值的准确率对比')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: 使用 scikit-learn 的 KNN\n",
    "\n",
    "### 4.1 创建 KNN 分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 创建 KNN 分类器\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    # 训练模型（注意：KNN 是惰性学习，训练过程只是存储数据）\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    # 在训练集和测试集上预测\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    # 计算准确率\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"KNN 分类器 (K=5):\")\n",
    "print(f\"  训练集准确率: {train_acc:.4f}\")\n",
    "print(f\"  测试集准确率: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 寻找最优 K 值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 尝试不同的 K 值\n",
    "k_values = list(range(1, 31, 2))  # 1, 3, 5, ..., 29\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# 遍历不同的 K 值，记录训练集和测试集的准确率\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    train_scores.append(knn.score(X_train, y_train))\n",
    "    test_scores.append(knn.score(X_test, y_test))\n",
    "\n",
    # 找到最佳 K 值\n",
    "best_k = k_values[np.argmax(test_scores)]\n",
    "best_score = max(test_scores)\n",
    "\n",
    print(f\"最佳 K 值: {best_k}\")\n",
    "print(f\"最佳测试集准确率: {best_score:.4f}\")\n",
    "\n",
    # 绘制 K 值与准确率的关系\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_values, train_scores, 'o-', label='训练集准确率', linewidth=2)\n",
    "plt.plot(k_values, test_scores, 's-', label='测试集准确率', linewidth=2)\n",
    "plt.axvline(x=best_k, color='green', linestyle='--', label=f'最佳 K={best_k}')\n",
    "plt.xlabel('K 值')\n",
    "plt.ylabel('准确率')\n",
    "plt.title('K 值对模型性能的影响')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 加权 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 创建两个 KNN 模型：均匀权重和距离权重\n",
    "\n",
    # 创建均匀权重的 KNN (weights='uniform')\n",
    "knn_uniform = KNeighborsClassifier(n_neighbors=best_k, weights='uniform')\n",
    "\n",
    # 创建距离权重的 KNN (weights='distance')\n",
    "knn_distance = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
    "\n",
    # 训练并评估\n",
    "knn_uniform.fit(X_train, y_train)\n",
    "knn_distance.fit(X_train, y_train)\n",
    "\n",
    "uniform_acc = knn_uniform.score(X_test, y_test)\n",
    "distance_acc = knn_distance.score(X_test, y_test)\n",
    "\n",
    print(\"权重策略比较:\")\n",
    "print(f\"  均匀权重 (uniform): {uniform_acc:.4f}\")\n",
    "print(f\"  距离权重 (distance): {distance_acc:.4f}\")\n",
    "\n",
    # 可视化比较\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(['均匀权重', '距离权重'], [uniform_acc, distance_acc], \n",
    "              alpha=0.7, edgecolor='black')\n",
    "plt.ylabel('准确率')\n",
    "plt.title('不同权重策略的性能比较')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    # 在柱子上显示数值\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.4f}',\n",
    "             ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 不同距离度量的比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 比较不同的距离度量\n",
    "metrics = ['euclidean', 'manhattan', 'minkowski']\n",
    "results = []\n",
    "\n",
    "for metric in metrics:\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k, metric=metric)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = knn.score(X_train, y_train)\n",
    "    test_acc = knn.score(X_test, y_test)\n",
    "    \n",
    "    results.append({\n",
    "        'metric': metric,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"不同距离度量的比较:\")\n",
    "print(results_df)\n",
    "\n",
    # 可视化\n",
    "plt.figure(figsize=(10, 5))\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, results_df['train_acc'], width, label='训练集准确率', alpha=0.7)\n",
    "plt.bar(x + width/2, results_df['test_acc'], width, label='测试集准确率', alpha=0.7)\n",
    "\n",
    "plt.xlabel('距离度量')\n",
    "plt.ylabel('准确率')\n",
    "plt.title('不同距离度量的性能比较')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: 模型评估与可视化\n",
    "\n",
    "### 5.1 使用最佳模型进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    # 使用最佳参数创建模型\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
    "\n",
    # 训练模型并预测\n",
    "best_knn.fit(X_train, y_train)\n",
    "y_pred_best = best_knn.predict(X_test)\n",
    "\n",
    # 显示分类报告\n",
    "print(\"分类报告:\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "print(f\"测试集准确率: {accuracy_score(y_test, y_pred_best):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 混淆矩阵可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    # 计算混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    # 可视化混淆矩阵\n",
    "plt.figure(figsize=(10, 8))\n",
    "# 使用 seaborn 绘制热力图\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.xlabel('预测类别')\n",
    "plt.ylabel('真实类别')\n",
    "plt.title('混淆矩阵 - 手写数字识别')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 可视化预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    # 找出预测正确和错误的样本\n",
    "correct_indices = np.where(y_test == y_pred_best)[0]\n",
    "incorrect_indices = np.where(y_test != y_pred_best)[0]\n",
    "\n",
    "print(f\"预测正确数量: {len(correct_indices)}\")\n",
    "print(f\"预测错误数量: {len(incorrect_indices)}\")\n",
    "\n",
    # 可视化一些预测结果\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "\n",
    # 第一行: 预测正确的样本\n",
    "for i in range(5):\n",
    "    idx = correct_indices[i]\n",
    "    img = X_test[idx].reshape(8, 8)\n",
    "    axes[0, i].imshow(img, cmap='gray')\n",
    "    axes[0, i].set_title(f'真实:{y_test[idx]}, 预测:{y_pred_best[idx]}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    # 第二行: 预测错误的样本\n",
    "for i in range(5):\n",
    "    if i < len(incorrect_indices):\n",
    "        idx = incorrect_indices[i]\n",
    "        img = X_test[idx].reshape(8, 8)\n",
    "        axes[1, i].imshow(img, cmap='gray')\n",
    "        axes[1, i].set_title(f'真实:{y_test[idx]}, 预测:{y_pred_best[idx]}', color='red')\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    axes[0, 0].set_ylabel('预测正确', fontsize=12)\n",
    "axes[1, 0].set_ylabel('预测错误', fontsize=12)\n",
    "plt.suptitle('KNN 预测结果示例', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 错误分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 分析哪些数字最容易混淆\n",
    "error_analysis = []\n",
    "for true_label in range(10):\n",
    "    for pred_label in range(10):\n",
    "        if true_label != pred_label:\n",
    "            count = cm[true_label, pred_label]\n",
    "            if count > 0:\n",
    "                error_analysis.append({\n",
    "                    'true': true_label,\n",
    "                    'pred': pred_label,\n",
    "                    'count': count\n",
    "                })\n",
    "\n",
    # 按错误数量排序\n",
    "error_analysis = sorted(error_analysis, key=lambda x: x['count'], reverse=True)\n",
    "\n",
    "print(\"最常见的错误分类（前10个）:\")\n",
    "for error in error_analysis[:10]:\n",
    "    print(f\"数字 {error['true']} 被误分类为 {error['pred']}: {error['count']} 次\")\n",
    "\n",
    # 可视化前5个最常见的错误\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(error_analysis[:5])), \n",
    "        [e['count'] for e in error_analysis[:5]],\n",
    "        alpha=0.7, edgecolor='black')\n",
    "plt.xticks(range(len(error_analysis[:5])), \n",
    "           [f\"{e['true']}→{e['pred']}\" for e in error_analysis[:5]])\n",
    "plt.xlabel('错误分类 (真实→预测)')\n",
    "plt.ylabel('错误次数')\n",
    "plt.title('最常见的错误分类')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: 挑战练习\n",
    "\n",
    "### 6.1 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    # 使用 5 折交叉验证评估模型\n",
    "cv_scores = cross_val_score(best_knn, X, y, cv=5)\n",
    "\n",
    "print(\"5 折交叉验证结果:\")\n",
    "print(f\"每折分数: {cv_scores}\")\n",
    "print(f\"平均分数: {cv_scores.mean():.4f}\")\n",
    "print(f\"标准差: {cv_scores.std():.4f}\")\n",
    "\n",
    # 可视化\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(1, 6), cv_scores, alpha=0.7, edgecolor='black')\n",
    "plt.axhline(y=cv_scores.mean(), color='red', linestyle='--', \n",
    "            label=f'平均分: {cv_scores.mean():.4f}')\n",
    "plt.xlabel('折数')\n",
    "plt.ylabel('准确率')\n",
    "plt.title('5 折交叉验证结果')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 决策边界可视化（简化版）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    # 使用 PCA 将数据降维到 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_train_2d = pca.fit_transform(X_train)\n",
    "X_test_2d = pca.transform(X_test)\n",
    "\n",
    # 在 2D 数据上训练 KNN\n",
    "knn_2d = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
    "knn_2d.fit(X_train_2d, y_train)\n",
    "\n",
    # 创建网格\n",
    "x_min, x_max = X_train_2d[:, 0].min() - 1, X_train_2d[:, 0].max() + 1\n",
    "y_min, y_max = X_train_2d[:, 1].min() - 1, X_train_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    # 预测网格\n",
    "Z = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    # 绘制决策边界\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    # 左图: 训练集\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train,\n",
    "                      cmap='tab10', alpha=0.6, s=30)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='tab10')\n",
    "plt.xlabel('主成分 1')\n",
    "plt.ylabel('主成分 2')\n",
    "plt.title('训练集 - PCA 降维后的决策边界')\n",
    "plt.colorbar(scatter, label='数字')\n",
    "\n",
    # 右图: 测试集\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(X_test_2d[:, 0], X_test_2d[:, 1], c=y_test,\n",
    "                      cmap='tab10', alpha=0.6, s=30)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='tab10')\n",
    "plt.xlabel('主成分 1')\n",
    "plt.ylabel('主成分 2')\n",
    "plt.title('测试集 - PCA 降维后的决策边界')\n",
    "plt.colorbar(scatter, label='数字')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 性能分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "import time\n",
    "\n",
    # 测试不同 K 值的预测时间\n",
    "k_values = [1, 5, 11, 21, 31, 51]\n",
    "prediction_times = []\n",
    "\n",
    "print(\"测量不同 K 值的预测时间...\\n\")\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # 测量预测时间\n",
    "    start = time.time()\n",
    "    knn.predict(X_test)\n",
    "    end = time.time()\n",
    "    \n",
    "    elapsed = end - start\n",
    "    prediction_times.append(elapsed)\n",
    "    print(f\"K={k:2d}: 预测时间 = {elapsed:.4f} 秒\")\n",
    "\n",
    # 绘制结果\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_values, prediction_times, 'o-', linewidth=2)\n",
    "plt.xlabel('K 值')\n",
    "plt.ylabel('预测时间 (秒)')\n",
    "plt.title('K 值对预测时间的影响')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    print(\"\\n结论:\")\n",
    print(\"- KNN 的预测时间随着 K 值增加略有增加\")\n",
    "print(\"- KNN 的主要时间开销是距离计算，这与 K 值关系不大\")\n",
    "print(\"- K 值的增加会导致更多的邻居需要考虑，但影响相对较小\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 特征重要性分析（基于特征子集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 测试使用不同特征数量时的性能\n",
    "feature_percentages = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "feature_accuracies = []\n",
    "\n",
    "print(\"测试不同特征数量的性能...\\n\")\n",
    "for percentage in feature_percentages:\n",
    "    # 随机选择特征子集\n",
    "    n_features = int(X.shape[1] * percentage)\n",
    "    feature_indices = np.random.choice(X.shape[1], n_features, replace=False)\n",
    "    \n",
    "    X_sub = X[:, feature_indices]\n",
    "    \n",
    "    # 划分数据集\n",
    "    X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(\n",
    "        X_sub, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # 归一化\n",
    "    X_train_sub = X_train_sub / 16.0\n",
    "    X_test_sub = X_test_sub / 16.0\n",
    "    \n",
    "    # 训练和评估\n",
    "    knn_sub = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    knn_sub.fit(X_train_sub, y_train_sub)\n",
    "    acc = knn_sub.score(X_test_sub, y_test_sub)\n",
    "    \n",
    "    feature_accuracies.append(acc)\n",
    "    print(f\"使用 {percentage*100:.0f}% 特征: 准确率 = {acc:.4f}\")\n",
    "\n",
    # 可视化\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot([p*100 for p in feature_percentages], feature_accuracies, 'o-', linewidth=2)\n",
    "plt.xlabel('使用特征比例 (%)')\n",
    "plt.ylabel('准确率')\n",
    "plt.title('特征数量对 KNN 性能的影响')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 KNN 回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    # 创建一个回归问题：预测数字的某种属性\n",
    # 这里我们使用数字的平均像素值作为目标\n",
    "y_reg = X.mean(axis=1)  # 每个图像的平均像素值\n",
    "\n",
    # 划分数据集\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_normalized, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    # 训练 KNN 回归\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_reg.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg = knn_reg.predict(X_test_reg)\n",
    "\n",
    # 评估\n",
    "mse_reg = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "print(f\"KNN 回归 MSE: {mse_reg:.4f}\")\n",
    "\n",
    # 可视化\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_reg, y_pred_reg, alpha=0.5)\n",
    "plt.plot([y_test_reg.min(), y_test_reg.max()], \n",
    "         [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\n",
    "plt.xlabel('真实平均像素值')\n",
    "plt.ylabel('预测平均像素值')\n",
    "plt.title('KNN 回归预测')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "恭喜你完成了 KNN 实验！在本实验中，你学习了：\n",
    "\n",
    "1. ✅ **KNN 原理**: 基于最近邻居的多数投票\n",
    "2. ✅ **距离度量**: 欧氏距离、曼哈顿距离\n",
    "3. ✅ **手动实现**: 从零实现 KNN 分类器\n",
    "4. ✅ **scikit-learn KNN**: 使用 KNeighborsClassifier\n",
    "5. ✅ **K 值选择**: 找到最优的邻居数量\n",
    "6. ✅ **模型评估**: 准确率、混淆矩阵、交叉验证\n",
    "\n",
    "### 关键要点\n",
    "\n",
    "- **K 值选择**: K 太小容易过拟合，K 太大容易欠拟合\n",
    "- **距离度量**: 欧氏距离最常用，曼哈顿距离对异常值更鲁棒\n",
    "- **加权投票**: 距离权重通常比均匀权重效果好\n",
    "- **特征缩放**: KNN 对特征尺度敏感，需要归一化\n",
    "- **计算成本**: KNN 是惰性学习，预测时需要计算大量距离\n",
    "\n",
    "### 进一步学习\n",
    "\n",
    "- 尝试其他距离度量（如余弦相似度）\n",
    "- 学习 KD 树和 Ball 树等加速算法\n",
    "- 探索 KNN 在回归问题中的应用 (KNeighborsRegressor)\n",
    "- 研究维度灾难及其缓解方法\n",
    "- 了解最近邻搜索的优化技术（如局部敏感哈希）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}