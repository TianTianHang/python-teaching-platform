{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: 逻辑回归实践\n",
    "\n",
    "## 实验概述\n",
    "\n",
    "在本实验中，你将使用 **Breast Cancer 数据集**来学习逻辑回归的实现和应用。这个数据集包含 569 个乳腺肿瘤样本，每个样本有 30 个特征，目标是判断肿瘤是良性还是恶性。\n",
    "\n",
    "### 实验目标\n",
    "\n",
    "1. 理解逻辑回归的原理\n",
    "2. 实现 Sigmoid 函数\n",
    "3. 实现二分类交叉熵损失\n",
    "4. 手动实现逻辑回归模型\n",
    "5. 使用 scikit-learn 的逻辑回归\n",
    "6. 绘制 ROC 曲线和混淆矩阵\n",
    "\n",
    "### 数据集信息\n",
    "\n",
    "- **样本数量**: 569\n",
    "- **特征数量**: 30\n",
    "- **特征**: 肿瘤尺寸、纹理、平滑度、对称性等\n",
    "- **目标**: 0=良性, 1=恶性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: 数据加载与探索\n",
    "\n",
    "### 1.1 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, \n",
    "                            classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"库导入成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 加载 Breast Cancer 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 加载数据集\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "feature_names = cancer.feature_names\n",
    "target_names = cancer.target_names\n",
    "\n",
    "print(\"数据集信息:\")\n",
    "print(f\"样本数量: {X.shape[0]}\")\n",
    "print(f\"特征数量: {X.shape[1]}\")\n",
    "print(f\"类别数量: {len(np.unique(y))}\")\n",
    "print(f\"类别名称: {target_names}\")\n",
    "print(f\"良性样本: {np.sum(y == 0)} 个\")\n",
    "print(f\"恶性样本: {np.sum(y == 1)} 个\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 创建 DataFrame\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(\"前5行数据:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n数据统计信息:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 数据可视化\n",
    "\n",
    "**任务**: 查看几个重要特征的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 选择几个重要特征进行可视化\n",
    "important_features = ['mean radius', 'mean texture', 'mean smoothness', 'mean compactness']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(important_features):\n",
    "    # 绘制两个类别的分布\n",
    "    malignant = df[df['target'] == 1]\n",
    "    benign = df[df['target'] == 0]\n",
    "    \n",
    "    sns.kdeplot(data=benign[feature], ax=axes[idx], label='良性', color='blue', alpha=0.7)\n",
    "    sns.kdeplot(data=malignant[feature], ax=axes[idx], label='恶性', color='red', alpha=0.7)\n",
    "    \n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('密度')\n",
    "    axes[idx].set_title(f'{feature} 分布')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('重要特征分布', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 划分数据集 (80% 训练, 20% 测试)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape}\")\n",
    "print(f\"测试集大小: {X_test.shape}\")\n",
    "print(f\"\\n训练集类别分布: {np.bincount(y_train)}\")\n",
    "print(f\"测试集类别分布: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 特征标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 创建标准化器\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 标准化特征\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"标准化完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: 核心函数实现\n",
    "\n",
    "### 2.1 Sigmoid 函数\n",
    "\n",
    "**任务**: 实现 Sigmoid 函数 $\sigma(z) = \\frac{1}{1 + e^{-z}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Sigmoid 函数\n",
    "    \n",
    "    参数:\n",
    "    z: 输入值（可以是标量或数组）\n",
    "    \n",
    "    返回:\n",
    "    Sigmoid 函数的值（0到1之间）\n",
    "    \"\"\"\n",
    "    # 避免 log(0) 的情况\n",
    "    z = np.clip(z, -250, 250)  # 限制范围防止溢出\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# 测试 Sigmoid 函数\n",
    "z_values = np.array([-5, 0, 5])\n",
    "sigmoid_results = sigmoid(z_values)\n",
    "print(f\"Sigmoid 函数测试:\")\n",
    "for z, result in zip(z_values, sigmoid_results):\n",
    "    print(f\"  σ({z:.1f}) = {result:.4f}\")\n",
    "print(f\"\\n当 z → -∞, σ(z) → {sigmoid(-1000):.6f}\")\n",
    "print(f\"当 z → +∞, σ(z) → {sigmoid(1000):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 实现前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def forward_propagation(X, theta):\n",
    "    \"\"\"\n",
    "    逻辑回归前向传播\n",
    "    \n",
    "    参数:\n",
    "    X: 特征矩阵 (m, n+1)，包含截距项\n",
    "    theta: 参数向量 (n+1,)\n",
    "    \n",
    "    返回:\n",
    "    概率值 (m,)\n",
    "    \"\"\"\n",
    "    # 计算线性组合并应用 Sigmoid 函数\n",
    "    z = np.dot(X, theta)\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 实现二分类交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算二分类交叉熵损失\n",
    "    \n",
    "    参数:\n",
    "    y_true: 真实标签 (0或1) (m,)\n",
    "    y_pred: 预测概率 (0到1之间) (m,)\n",
    "    \n",
    "    返回:\n",
    "    平均损失\n",
    "    \"\"\"\n",
    "    # 避免 log(0) 的情况\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    \n",
    "    # 计算二分类交叉熵\n",
    "    # 当 y_true=1 时: -log(y_pred)\n",
    "    # 当 y_true=0 时: -log(1 - y_pred)\n",
    "    m = len(y_true)\n",
    "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# 测试交叉熵损失\n",
    "y_true = np.array([1, 0, 1, 1])\n",
    "y_pred = np.array([0.9, 0.1, 0.8, 0.7])\n",
    "loss = binary_cross_entropy(y_true, y_pred)\n",
    "print(f\"交叉熵损失测试: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 实现梯度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def compute_gradient(X, y, theta):\n",
    "    \"\"\"\n",
    "    计算逻辑回归的梯度\n",
    "    \n",
    "    参数:\n",
    "    X: 特征矩阵 (m, n+1)\n",
    "    y: 真实标签 (m,)\n",
    "    theta: 参数 (n+1,)\n",
    "    \n",
    "    返回:\n",
    "    梯度 (n+1,)\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    \n",
    "    # 计算预测概率\n",
    "    y_pred = forward_propagation(X, theta)\n",
    "    \n",
    "    # 计算误差\n",
    "    error = y_pred - y\n",
    "    \n",
    "    # 计算梯度\n",
    "    # gradient = (1/m) * X^T @ (y_pred - y)\n",
    "    gradient = (1/m) * np.dot(X.T, error)\n",
    "    \n",
    "    return gradient\n",
    "\n",
    "# 测试梯度计算\n",
    "X_train_with_intercept = np.c_[np.ones((X_train_scaled.shape[0], 1)), X_train_scaled]\n",
    "test_theta = np.zeros(X_train_with_intercept.shape[1])\n",
    "test_gradient = compute_gradient(X_train_with_intercept, y_train, test_theta)\n",
    "print(f\"梯度形状: {test_gradient.shape}\")\n",
    "print(f\"梯度前5个值: {test_gradient[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: 手动实现逻辑回归\n",
    "\n",
    "### 3.1 实现梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def logistic_regression_gradient_descent(X, y, theta, alpha, num_iterations):\n",
    "    \"\"\"\n",
    "    逻辑回归梯度下降算法\n",
    "    \n",
    "    参数:\n",
    "    X: 特征矩阵\n",
    "    y: 真实标签\n",
    "    theta: 初始参数\n",
    "    alpha: 学习率\n",
    "    num_iterations: 迭代次数\n",
    "    \n",
    "    返回:\n",
    "    优化后的参数和损失历史\n",
    "    \"\"\"\n",
    "    # 添加截距项\n",
    "    m = len(y)\n",
    "    X_with_intercept = np.c_[np.ones((m, 1)), X]\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # 计算当前损失\n",
    "        y_pred = forward_propagation(X_with_intercept, theta)\n",
    "        current_loss = binary_cross_entropy(y, y_pred)\n",
    "        loss_history.append(current_loss)\n",
    "        \n",
    "        # 计算梯度\n",
    "        gradient = compute_gradient(X_with_intercept, y, theta)\n",
    "        \n",
    "        # 更新参数\n",
    "        theta = theta - alpha * gradient\n",
    "        \n",
    "        # 每100次迭代打印一次损失\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"迭代 {i+1}/{num_iterations}, 损失: {current_loss:.4f}\")\n",
    "    \n",
    "    return theta, loss_history\n",
    "\n",
    "# 测试梯度下降\n",
    "alpha = 0.01  # 学习率\n",
    "num_iterations = 1000  # 迭代次数\n",
    "\n",
    "initial_theta = np.zeros(X_train_scaled.shape[1] + 1)\n",
    "\n",
    "print(\"开始逻辑回归梯度下降...\")\n",
    "theta, loss_history = logistic_regression_gradient_descent(\n",
    "    X_train_scaled, y_train, initial_theta, alpha, num_iterations\n",
    ")\n",
    "\n",
    "print(f\"\\n优化后的参数:\")\n",
    "print(f\"截距: {theta[0]:.4f}\")\n",
    "for i, coef in enumerate(theta[1:], 1):\n",
    "    print(f\"{feature_names[i-1]}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 可视化损失曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('迭代次数')\n",
    "plt.ylabel('损失 (交叉熵)')\n",
    "plt.title('逻辑回归损失曲线')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 实现预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def predict_proba(X, theta):\n",
    "    \"\"\"\n",
    "    预测概率\n",
    "    \n",
    "    参数:\n",
    "    X: 特征矩阵 (m, n)\n",
    "    theta: 参数向量 (n+1,)\n",
    "    \n",
    "    返回:\n",
    "    概率值 (m,)\n",
    "    \"\"\"\n",
    "    # 添加截距项并计算概率\n",
    "    X_with_intercept = np.c_[np.ones((len(X), 1)), X]\n",
    "    return forward_propagation(X_with_intercept, theta)\n",
    "\n",
    "def predict(X, theta, threshold=0.5):\n",
    "    \"\"\"\n",
    "    预测类别\n",
    "    \n",
    "    参数:\n",
    "    X: 特征矩阵\n",
    "    theta: 参数\n",
    "    threshold: 分类阈值\n",
    "    \n",
    "    返回:\n",
    "    预测类别 (0或1)\n",
    "    \"\"\"\n",
    "    probs = predict_proba(X, theta)\n",
    "    return (probs >= threshold).astype(int)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_test_pred_manual = predict(X_test_scaled, theta)\n",
    "y_test_pred_proba = predict_proba(X_test_scaled, theta)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy_manual = accuracy_score(y_test, y_test_pred_manual)\n",
    "\n",
    "print(f\"手动实现的逻辑回归:\")\n",
    "print(f\"  测试集准确率: {accuracy_manual:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 分类阈值分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 测试不同的阈值\n",
    "thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = predict(X_test_scaled, theta, threshold)\n",
    "    acc = accuracy_score(y_test, y_pred_thresh)\n",
    "    prec = precision_score(y_test, y_pred_thresh)\n",
    "    rec = recall_score(y_test, y_pred_thresh)\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, accuracies, 'o-', label='准确率')\n",
    "plt.plot(thresholds, precisions, 's-', label='精确率')\n",
    "plt.plot(thresholds, recalls, '^-', label='召回率')\n",
    "plt.axvline(x=0.5, color='red', linestyle='--', label='默认阈值 0.5')\n",
    "plt.xlabel('分类阈值')\n",
    "plt.ylabel('指标值')\n",
    "plt.title('不同阈值下的模型性能')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: 使用 scikit-learn 的逻辑回归\n",
    "\n",
    "### 4.1 创建并训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 创建逻辑回归模型\n",
    "sklearn_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# 训练模型\n",
    "sklearn_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 在测试集上预测\n",
    "y_test_pred_sklearn = sklearn_lr.predict(X_test_scaled)\n",
    "y_test_pred_proba_sklearn = sklearn_lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 计算指标\n",
    "accuracy_sklearn = accuracy_score(y_test, y_test_pred_sklearn)\n",
    "\n",
    "print(f\"scikit-learn 逻辑回归:\")\n",
    "print(f\"  测试集准确率: {accuracy_sklearn:.4f}\")\n",
    "\n",
    "# 比较两种方法\n",
    "print(f\"\\n两种方法比较:\")\n",
    "print(f\"  准确率差值: {abs(accuracy_manual - accuracy_sklearn):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 计算混淆矩阵\n",
    "cm_manual = confusion_matrix(y_test, y_test_pred_manual)\n",
    "cm_sklearn = confusion_matrix(y_test, y_test_pred_sklearn)\n",
    "\n",
    "# 显示混淆矩阵\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 手动实现的混淆矩阵\n",
    "sns.heatmap(cm_manual, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_names, yticklabels=target_names, ax=axes[0])\n",
    "axes[0].set_title('手动实现的逻辑回归')\n",
    "axes[0].set_xlabel('预测类别')\n",
    "axes[0].set_ylabel('真实类别')\n",
    "\n",
    "# sklearn的混淆矩阵\n",
    "sns.heatmap(cm_sklearn, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_names, yticklabels=target_names, ax=axes[1])\n",
    "axes[1].set_title('scikit-learn 逻辑回归')\n",
    "axes[1].set_xlabel('预测类别')\n",
    "axes[1].set_ylabel('真实类别')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ROC 曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 计算手动实现的 ROC 曲线\n",
    "fpr_manual, tpr_manual, _ = roc_curve(y_test, y_test_pred_proba)\n",
    "roc_auc_manual = auc(fpr_manual, tpr_manual)\n",
    "\n",
    "# 计算 sklearn 的 ROC 曲线\n",
    "fpr_sklearn, tpr_sklearn, _ = roc_curve(y_test, y_test_pred_proba_sklearn)\n",
    "roc_auc_sklearn = auc(fpr_sklearn, tpr_sklearn)\n",
    "\n",
    "# 绘制 ROC 曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "# 绘制两条 ROC 曲线\n",
    "plt.plot(fpr_manual, tpr_manual, label=f'手动实现 (AUC = {roc_auc_manual:.4f})', linewidth=2)\n",
    "plt.plot(fpr_sklearn, tpr_sklearn, label=f'sklearn (AUC = {roc_auc_sklearn:.4f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('假阳性率')\n",
    "plt.ylabel('真阳性率')\n",
    "plt.title('ROC 曲线比较')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 预测概率分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "# 绘制预测概率分布\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 第一个子图：手动实现\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_test_pred_proba[y_test == 1], bins=30, alpha=0.7, label='恶性', color='red')\n",
    "plt.hist(y_test_pred_proba[y_test == 0], bins=30, alpha=0.7, label='良性', color='blue')\n",
    "plt.axvline(x=0.5, color='black', linestyle='--', label='阈值 0.5')\n",
    "plt.xlabel('预测概率')\n",
    "plt.ylabel('样本数')\n",
    "plt.title('手动实现 - 预测概率分布')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 第二个子图：sklearn实现\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y_test_pred_proba_sklearn[y_test == 1], bins=30, alpha=0.7, label='恶性', color='red')\n",
    "plt.hist(y_test_pred_proba_sklearn[y_test == 0], bins=30, alpha=0.7, label='良性', color='blue')\n",
    "plt.axvline(x=0.5, color='black', linestyle='--', label='阈值 0.5')\n",
    "plt.xlabel('预测概率')\n",
    "plt.ylabel('样本数')\n",
    "plt.title('sklearn实现 - 预测概率分布')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 详细分类报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "print(\"手动实现的逻辑回归分类报告:\")\n",
    "print(classification_report(y_test, y_test_pred_manual, target_names=target_names))\n",
    "\n",
    "print(\"\\nscikit-learn 逻辑回归分类报告:\")\n",
    "print(classification_report(y_test, y_test_pred_sklearn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: 挑战练习\n",
    "\n",
    "### 5.1 L2 正则化实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "def logistic_regression_with_l2(X, y, theta, alpha, lambda_reg, num_iterations):\n",
    "    \"\"\"\n",
    "    带L2正则化的逻辑回归\n",
    "    \n",
    "    参数:\n",
    "    lambda_reg: L2正则化系数\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    X_with_intercept = np.c_[np.ones((m, 1)), X]\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # 计算当前损失\n",
    "        y_pred = forward_propagation(X_with_intercept, theta)\n",
    "        cross_entropy = binary_cross_entropy(y, y_pred)\n",
    "        # 添加L2正则项（不惩罚截距项）\n",
    "        l2_reg = (lambda_reg / (2*m)) * np.sum(theta[1:] ** 2)\n",
    "        total_loss = cross_entropy + l2_reg\n",
    "        loss_history.append(total_loss)\n",
    "        \n",
    "        # 计算梯度\n",
    "        gradient = compute_gradient(X_with_intercept, y, theta)\n",
    "        # 添加L2正则的梯度\n",
    "        gradient[1:] += (lambda_reg/m) * theta[1:]\n",
    "        \n",
    "        # 更新参数\n",
    "        theta = theta - alpha * gradient\n",
    "    \n",
    "    return theta, loss_history\n",
    "\n",
    "# 尝试不同的正则化系数\n",
    "lambda_values = [0.001, 0.01, 0.1, 1.0]\n",
    "results = []\n",
    "\n",
    "print(\"L2正则化效果:\")\n",
    "for lambda_reg in lambda_values:\n",
    "    theta_l2, _ = logistic_regression_with_l2(\n",
    "        X_train_scaled, y_train, initial_theta, alpha, lambda_reg, num_iterations\n",
    "    )\n",
    "    \n",
    "    y_pred_l2 = predict(X_test_scaled, theta_l2)\n",
    "    accuracy_l2 = accuracy_score(y_test, y_pred_l2)\n",
    "    \n",
    "    results.append({\n",
    "        'lambda': lambda_reg,\n",
    "        'accuracy': accuracy_l2\n",
    "    })\n",
    "    \n",
    "    print(f\"lambda={lambda_reg}: 准确率 = {accuracy_l2:.4f}\")\n",
    "\n",
    "# 找到最佳正则化系数\n",
    "best_result = max(results, key=lambda x: x['accuracy'])\n",
    "print(f\"\\n最佳 lambda: {best_result['lambda']}, 准确率: {best_result['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 使用 sklearn 的正则化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 创建带L2正则化的模型\n",
    "lr_l2 = LogisticRegression(penalty='l2', C=1/best_result['lambda'], \n",
    "                          solver='lbfgs', max_iter=1000, random_state=42)\n",
    "lr_l2.fit(X_train_scaled, y_train)\n",
    "y_pred_l2_sklearn = lr_l2.predict(X_test_scaled)\n",
    "accuracy_l2_sklearn = accuracy_score(y_test, y_pred_l2_sklearn)\n",
    "\n",
    "print(f\"sklearn L2正则化逻辑回归:\")\n",
    "print(f\"  测试集准确率: {accuracy_l2_sklearn:.4f}\")\n",
    "\n",
    "# 比较手动实现和 sklearn\n",
    "print(f\"\\nL2正则化实现比较:\")\n",
    "print(f\"  手动实现: {best_result['accuracy']:.4f}\")\n",
    "print(f\"  sklearn实现: {accuracy_l2_sklearn:.4f}\")\n",
    "print(f\"  差值: {abs(best_result['accuracy'] - accuracy_l2_sklearn):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 特征重要性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 提取 sklearn 模型的系数\n",
    "feature_importance = np.abs(sklearn_lr.coef_[0])\n",
    "\n",
    "# 创建 DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': sklearn_lr.coef_[0],\n",
    "    'absolute_importance': feature_importance\n",
    "}).sort_values('absolute_importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 最重要的特征:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(importance_df['feature'][:10], importance_df['coefficient'][:10])\n",
    "plt.xlabel('系数值')\n",
    "plt.ylabel('特征')\n",
    "plt.title('逻辑回归特征系数 (Top 10)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 决策边界可视化（简化版）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 使用 PCA 降维\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# 在降维后的数据上训练模型\n",
    "lr_pca = LogisticRegression(random_state=42)\n",
    "lr_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# 创建网格\n",
    "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# 预测\n",
    "Z = lr_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# 绘制\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='RdBu')\n",
    "scatter = plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_test, \n",
    "                       cmap='RdBu', edgecolors='black')\n",
    "plt.xlabel('主成分 1')\n",
    "plt.ylabel('主成分 2')\n",
    "plt.title('决策边界（PCA 降维到2D）')\n",
    "plt.colorbar(scatter, label='类别')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 参考答案 =====\n",
    "# 使用 5 折交叉验证评估模型\n",
    "cv_scores = cross_val_score(sklearn_lr, X, y, cv=5)\n",
    "\n",
    "print(\"5 折交叉验证结果:\")\n",
    "print(f\"每折分数: {cv_scores}\")\n",
    "print(f\"平均分数: {cv_scores.mean():.4f}\")\n",
    "print(f\"标准差: {cv_scores.std():.4f}\")\n",
    "\n",
    # 可视化\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(1, 6), cv_scores, alpha=0.7, edgecolor='black')\n",
    "plt.axhline(y=cv_scores.mean(), color='red', linestyle='--',\n",
    "            label=f'平均分: {cv_scores.mean():.4f}')\n",
    "plt.xlabel('折数')\n",
    "plt.ylabel('准确率')\n",
    "plt.title('5 折交叉验证结果')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 学习曲线分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 预填充代码 =====\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# 绘制学习曲线\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    sklearn_lr, X_train_scaled, y_train, cv=5, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    # 计算均值和标准差\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    # 绘制学习曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='r', label='训练集准确率')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='r')\n",
    "plt.plot(train_sizes, test_mean, 'o-', color='g', label='验证集准确率')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color='g')\n",
    "plt.xlabel('训练样本数')\n",
    "plt.ylabel('准确率')\n",
    "plt.title('学习曲线')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "恭喜你完成了逻辑回归实验！在本实验中，你学习了：\n",
    "\n",
    "1. ✅ **逻辑回归原理**: Sigmoid 函数、二分类交叉熵\n",
    "2. ✅ **手动实现**: 从零实现逻辑回归梯度下降\n",
    "3. ✅ **scikit-learn**: 使用 LogisticRegression 类\n",
    "4. ✅ **模型评估**: 准确率、混淆矩阵、ROC 曲线\n",
    "5. ✅ **正则化**: L2 正则化防止过拟合\n",
    "6. ✅ **特征分析**: 特征重要性分析\n",
    "\n",
    "### 关键要点\n",
    "\n",
    "- **Sigmoid 函数**: 将线性组合映射到 0-1 之间的概率\n",
    "- **交叉熵损失**: 衡量预测概率与真实标签之间的差距\n",
    "- **梯度下降**: 通过迭代更新参数最小化损失\n",
    "- **ROC 曲线**: 评估分类器在不同阈值下的性能\n",
    "- **特征系数**: 正系数增加恶性概率，负系数增加良性概率\n",
    "\n",
    "### 进一步学习\n",
    "\n",
    "- 尝试不同的分类阈值（不默认使用 0.5）\n",
    "- 学习逻辑回归在多分类中的应用（一对多）\n",
    "- 探索其他正则化方法（L1 正则化 - Lasso）\n",
    "- 学习概率校准技术（Platt scaling, Isotonic）\n",
    "- 了解决策边界及其几何意义"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}